{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qm5e53SlTBm3",
    "outputId": "9cc8939c-3856-4914-b217-8ee15d2f058d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from peft) (2.8.0+cu128)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.6)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m234.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.2-py3-none-any.whl (512 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m243.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m276.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow, hf-xet, fsspec, dill, multiprocess, huggingface-hub, tokenizers, transformers, datasets, bitsandbytes, accelerate, peft\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.12.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling fsspec-2025.12.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.12.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [peft]2m14/15\u001b[0m [peft]erate]s]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0 datasets-4.4.2 dill-0.4.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 multiprocess-0.70.18 peft-0.18.0 pyarrow-22.0.0 regex-2025.11.3 safetensors-0.7.0 tokenizers-0.22.1 transformers-4.57.3 xxhash-3.6.0\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.8.0+cu128)\n",
      "Requirement already satisfied: torchvision in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.23.0+cu128)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m157.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.1%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m147.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m154.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m173.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.1%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m177.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.0%2Bcu118-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m259.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m234.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m180.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m216.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m273.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m241.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m249.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m270.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m175.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m226.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (905.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.2/905.2 MB\u001b[0m \u001b[31m160.4 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m160.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.4.0\n",
      "\u001b[2K    Uninstalling triton-3.4.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.4.0\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cudnn-cu11]11]1]1]\n",
      "\u001b[2K    Found existing installation: torch 2.8.0+cu1280m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cudnn-cu11]\n",
      "\u001b[2K    Uninstalling torch-2.8.0+cu128:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]nn-cu11]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0+cu1280m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.23.0+cu128━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.23.0+cu128:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m13/15\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.23.0+cu1280m━━━━━\u001b[0m \u001b[32m13/15\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [torchaudio]5\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118 triton-3.3.1\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets peft accelerate bitsandbytes\n",
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpglkLvMbRyl"
   },
   "source": [
    "Load the dataset from hugging face https://huggingface.co/datasets/169Pi/indian_law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PW0YVMj1X3ND"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "b1c0f721617e412891fc5da53f80d054",
      "73040ef05563475eba6a7fc6b4dec500",
      "a60308756f024813a67239e7978cafec",
      "12aeeb1349d04cea98ec7728ae7ba6d2",
      "e5048fd751f14077bb1eabbf614f49d7",
      "8428771923ae40a281892cd57ce3610d",
      "5018c4b1fddd4d7598887c5ed953b23a",
      "c2d282888aa14995bf694dabf38b5fd8",
      "6e577a80eed342b99bbed8d357819695",
      "659012a1b859460681fae79f384a20f9",
      "b3a85c92897948c0af219dab8fe219e3",
      "21358af5e2304de99eb451b887194178",
      "7beb173011d14d53a4af746d6c4f17c7",
      "e752cec41b4f4721bf7de91aead1e9c8",
      "a2b7258c36a54db29658534ccf6f9196",
      "b11178c9eb6345f7acccb4364945c170",
      "e25dcee5dc454f2686a5dda5953bca2c",
      "406fe2406e114c138bd1cdab42e2d43c",
      "a9093f1ed697493e8a1793c379561104",
      "9706ef52c7344df0abc27510c69b8bae",
      "8a580e0b60f24a13b241eeab37f437f2",
      "548ee71a246c45a79671a05855ce33cd",
      "ed669c15885045969ceac20fc4d3a920",
      "56cc182bab934d25bbf9c58fd7c48918",
      "4878901af9034b90a4aeca3664418e7f",
      "a476180b84834b299abc15d9d10c266a",
      "141cf542cc8e4053b7e56a0d716edc22",
      "aac57d99af8e416a8f334d1552c6828a",
      "c6b6fe27c057443aaad751c60f741a51",
      "90df82aab4d54bcc84440860381614ac",
      "3105edfb44414d80ae3058d248691a4d",
      "4552c0690447446580e8d1bf9f8238f6",
      "1f113b48b236498f826ff4028b38f64e"
     ]
    },
    "id": "BwLbFwkIYBIC",
    "outputId": "381e3937-3912-43b3-ebfb-291a45966cb9"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"169Pi/indian_law\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVNKv-uoYJMG",
    "outputId": "e548d47a-7a1a-400b-910b-fe9a78506763"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Explain the legal provisions relating to biodiversity conservation under the Biological Diversity Act, 2002. How does the National Biodiversity Authority (NBA) regulate access to biological resources in India?',\n",
       " 'complex_cot': \"What are the legislations impacting biodiversity and the environment in India in the last five years? How does informed consent relate to biosecurity in environmental governance?\\n\\nTo cover these areas, I need to use appropriate academic sources, peer-reviewed articles, and legal documents. Let me think about how each of these areas is connected. First, the Biological Diversity Act, 2002 - I remember that it was a significant piece of legislation in India to address biodiversity conservation. It likely includes provisions on protected areas, conservation measures, and penalties for illegal activities related to biodiversity.\\n\\nThen, the role of the National Biodiversity Authority (NBA) - I recall that the NBA is a regulatory body established under the Biological Diversity Act. They probably oversee issues like access to biological resources, issuing permits, and enforcing related laws. Maybe they have a framework for how industries or researchers can access these resources, which is tied to informed consent.\\n\\nMoving on to legislations impacting biodiversity and the environment in the last five years. I think there have been some amendments or new laws. The Climate Change Act, 2021 comes to mind, which is broader but includes some biodiversity aspects. Also, there might be regulations under the Union Environment Ministry or state level that have been introduced. Maybe the Environment Protection Act or something else has been updated.\\n\\nRegarding informed consent and biosecurity, I think these are concepts that ensure that any access to biological resources is done with properauthorization and consideration of potential impacts. It's related to governance to prevent biohazards or unauthorized access. So, informed consent would involve informed decision-making by the relevant authorities before granting access, ensuring that the environmental and biosecurity implications are considered.\\n\\nPutting this together, I can structure the explanation by first detailing the legal provisions of the Biodiversity Act, then discussing NBA's role, followed by recent legislations, and finally explaining informed consent in the context of biosecurity. Each section should reference appropriate legal documents or academic sources to support the points made. Maybe also consider any challenges or issues that have arisen with these provisions, but the question doesn't ask for that, so perhaps just stick to the main points.\\n\\nNow, to find sources. The Biological Diversity Act, 2002 text will be needed. Then, the NBA's official website for their regulatory framework. For the last five years' legislations, look for recent amendments or new acts. Maybe the Environment Protection Amendment Act 2020? Or perhaps the National Repository of Regulations could have updates. For informed consent and biosecurity, academic articles or reports from organizations like the United Nations Environment Programme or governmental reports might be useful.\\n\\nPotential gaps: Are there nuances in the Biodiversity Act, 2002 that I might overlook? Also, how has the NBA implemented these regulations in practice? Maybe some case studies or reports on NBA's enforcement efforts. Additionally, I need to ensure that the information about informed consent is accurate and how it specifically relates to biosecurity in environmental governance, perhaps differentiating it from, say, informed consent in medical contexts.\\n\\nIn conclusion, the explanation should clearly outline the legal framework, the regulatory body's role, recent laws, and the concept of informed consent relating to biosecurity, supported by references to appropriate sources.\",\n",
       " 'response': \"**Understanding Biodiversity Conservation in India: An Overview**\\n\\nIndia has established a robust legal framework to protect its biodiversity, recognizing the importance of biological diversity to ecological health and economic sustainability. The Biological Diversity Act, 2002, is a cornerstone legislation that addresses biodiversity conservation through provisions related to protected areas, conservation measures, and penalizing illegal activities. This act also established the National Biodiversity Authority (NBA) as a regulatory body to oversee biodiversity-related matters.\\n\\n**Role of the National Biodiversity Authority (NBA)**\\n\\nThe NBA, established under the Biological Diversity Act, plays a crucial role in regulating access to biological resources. It issues permits, conductsrisk assessments, and enforces compliance with biodiversity laws. The NBA's framework ensures that industries and researchers can access biological resources while safeguarding ecological integrity, emphasizing informed consent and biosecurity.\\n\\n**Recent Legitations Impacting Biodiversity and Environment**\\n\\nIn the past five years, several legislations have been introduced to enhance biodiversity and environmental governance. Notable among these is the Climate Change Act, 2021, which integrates biodiversity considerations into climate strategies. Additionally, the Environment Protection Amendment Act of 2020 and state-level regulations have been updated to strengthen environmental protections and promote sustainable practices, reflecting a national commitment to ecological health.\\n\\n**Informed Consent and Biosecurity**\\n\\nInformed consent in environmental governance refers to the process where decision-makers assessments of potential environmental and biosecurity impacts are conducted before granting access to biological resources. This concept ensures that such access is responsible and avoid unintended ecological harm, aligning with biosecurity protocols to protect against biological hazards. It differs from informed consent in medical contexts by prioritizing environmental sustainability.\\n\\n**Conclusion**\\n\\nThe Biological Diversity Act, 2002, provides a comprehensive legal framework for biodiversity conservation in India, supported by the NBA's regulatory efforts. Recent legislations emphasize environmental protection, while informed consent ensures biosecurity in resource access. Together, these elements underscore India's commitment to sustainable biodiversity management and environmental governance.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ghy1hzVYgzk",
    "outputId": "81a6f404-4464-4aef-ed95-307f0952f333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 1 ---\n",
      "Prompt: Explain the legal provisions relating to biodiversity conservation under the Biological Diversity Act, 2002. How does the National Biodiversity Authority (NBA) regulate access to biological resources in India?\n",
      "Response: **Understanding Biodiversity Conservation in India: An Overview**\n",
      "\n",
      "India has established a robust legal framework to protect its biodiversity, recognizing the importance of biological diversity to ecological health and economic sustainability. The Biological Diversity Act, 2002, is a cornerstone legislation that addresses biodiversity conservation through provisions related to protected areas, conservation measures, and penalizing illegal activities. This act also established the National Biodiversity Authority (NBA) as a regulatory body to oversee biodiversity-related matters.\n",
      "\n",
      "**Role of the National Biodiversity Authority (NBA)**\n",
      "\n",
      "The NBA, established under the Biological Diversity Act, plays a crucial role in regulating access to biological resources. It issues permits, conductsrisk assessments, and enforces compliance with biodiversity laws. The NBA's framework ensures that industries and researchers can access biological resources while safeguarding ecological integrity, emphasizing informed consent and biosecurity.\n",
      "\n",
      "**Recent Legitations Impacting Biodiversity and Environment**\n",
      "\n",
      "In the past five years, several legislations have been introduced to enhance biodiversity and environmental governance. Notable among these is the Climate Change Act, 2021, which integrates biodiversity considerations into climate strategies. Additionally, the Environment Protection Amendment Act of 2020 and state-level regulations have been updated to strengthen environmental protections and promote sustainable practices, reflecting a national commitment to ecological health.\n",
      "\n",
      "**Informed Consent and Biosecurity**\n",
      "\n",
      "Informed consent in environmental governance refers to the process where decision-makers assessments of potential environmental and biosecurity impacts are conducted before granting access to biological resources. This concept ensures that such access is responsible and avoid unintended ecological harm, aligning with biosecurity protocols to protect against biological hazards. It differs from informed consent in medical contexts by prioritizing environmental sustainability.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "The Biological Diversity Act, 2002, provides a comprehensive legal framework for biodiversity conservation in India, supported by the NBA's regulatory efforts. Recent legislations emphasize environmental protection, while informed consent ensures biosecurity in resource access. Together, these elements underscore India's commitment to sustainable biodiversity management and environmental governance.\n",
      "\n",
      "--- Sample 2 ---\n",
      "Prompt: Explain the concept of 'workman' as defined under the Industrial Disputes Act, 1947, and how it applies to a software engineer employed on a contractual basis in Bangalore.\n",
      "Response: The concept of 'workman' under the Industrial Disputes Act, 1947, has evolved over time to include a broader range of professions, particularly in modern industries. In the context of Bangalore, where software engineering is prominent, professionals in this field are often classified as workmen under the Act. This classification is supported by Supreme Court rulings, such as the Bharat screening case, which have emphasized that IT professionals performing tasks akin to manufacturing processes in the IT sector are considered workmen.\n",
      "\n",
      "Key considerations include:\n",
      "\n",
      "1. **Definition Expansion**: The Act's traditional definition of a workman has been interpreted to include software engineers due to the integral role they play in the IT industry, even if theiremployment is contractual.\n",
      "\n",
      "2. **Employment Types**: Contract and casual employees are included. The distinction is more about the nature of the work and the industry's classification rather than the employment type.\n",
      "\n",
      "3. **jurisdictional Considerations**: While the Act's central government Advised jurisdiction, disputes are typically handled by state authorities. In Bangalore, software engineers may be classified as workmen under the Act's provisions.\n",
      "\n",
      "In conclusion, software engineers in Bangalore are recognized as workmen under the Industrial Disputes Act, covering both contractual and casual employees, due to the evolving interpretation of the Act to include modern professions.\n",
      "\n",
      "--- Sample 3 ---\n",
      "Prompt: What is the role of 'Judicial Precedent' in the interpretation of statutes, and how does 'Stare Decisis' affect the process?\n",
      "Response: **Role of Judicial Precedent and Stare Decisis in Interpreting Statutes**\n",
      "\n",
      "1. **Judicial Precedent**: This is the body of prior court decisions used as guidelines for interpreting and applying statutes. Judges refer to these precedents to inform their decisions, especially when a statute's meaning is ambiguous or unclear. Precedent helps maintain consistency and predictability in legal decisions, providing a foundation for future courts to follow similar principles.\n",
      "\n",
      "2. **Stare Decisis**: This principle, meaning \"to stand by what has been decided,\" requires courts to adhere to their own past decisions unless there are compelling reasons to override them. It ensures that legal interpretations remain consistent, reducing unpredictability and uncertainty in the law.\n",
      "\n",
      "3. **Interpretation Process**: Courts do not mechanically apply precedents but engage with both the text of statutes and prior rulings. They reconcile past decisions with current legal texts, deriving principles to inform their interpretations. This balance allows for reasoned application while maintaining legal coherence.\n",
      "\n",
      "4. **Common Law vs. Civil Law Systems**: In common law systems, judicial precedent plays a significant role due to the absence of extensive written codes in some areas. In contrast, civil law systems have detailed statutes, but judicial precedent still aids in clarifying ambiguities or conflicts within statutes.\n",
      "\n",
      "5. **Judicial Activism**: Even in cases where judges might impose their policy beyond a statute's text, they must follow prior precedents unless they justify overruling them. This ensures that decisions remain grounded in legal framework while allowing for necessary legal evolution.\n",
      "\n",
      "6. **Challenges**: While providing consistency, judicial precedent can sometimes lead to outdated or restrictive decisions, hindering legal progress. Courts must adapt to new situations, balancing consistency with the need for legal development.\n",
      "\n",
      "In conclusion, judicial precedent and stare decisis are crucial for maintaining a coherent and predictable legal system. They guide courts in interpreting statutes, ensuring consistency while allowing for reasoned evolution in the law.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    data = dataset[i]\n",
    "    prompt = data[\"prompt\"]\n",
    "    response = data[\"response\"]\n",
    "\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(\"Prompt:\", prompt)\n",
    "    print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrGPKbErbead"
   },
   "source": [
    "The dataset is in the format\n",
    "\n",
    "> {prompt : \" \",\n",
    "complex_cot : \" \",\n",
    "response : \" \"}\n",
    "\n",
    "We need to re-format the data in\n",
    "\n",
    "\n",
    "> {\n",
    "  \"instruction\": \" \",\n",
    "  \"input\": \" \",\n",
    "  \"output\": \" \"\n",
    "} style\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "l9Mf5cU3ZzKe"
   },
   "outputs": [],
   "source": [
    "# Re-formatting the dataset in required format\n",
    "\n",
    "def to_instruction_format(example):\n",
    "    return {\n",
    "        \"instruction\": (\n",
    "            \"Explain the following from a Company Secretary compliance \"\n",
    "            \"perspective under Indian law\"\n",
    "        ),\n",
    "        \"input\": example[\"prompt\"],\n",
    "        \"output\": example[\"response\"]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0e7156291fab461db23b43df05d1d9af",
      "196eca3cb3df4c54847f457e15bed1be",
      "88540ea0bb4b49d09cec3606a9f41bc4",
      "e3f868262f65454c9253b2cb1d104a50",
      "ef8907524dbe4e90af3449d32b75ae63",
      "0543b1d8f4064981b101cdca98114967",
      "980f2f13b1f242e6b8f7bcaedba9d19b",
      "5374fb4313f440adbc2b9afe3b5407c2",
      "c01095a1c46f4446860d55841c2baddd",
      "abea1734b11b48dbac39e573529a6899",
      "ddefb1fc45834cb5a22b9937572b96d7"
     ]
    },
    "id": "U_3Qt_iqcURn",
    "outputId": "15a57de3-3366-4071-e681-f89bf3938d12"
   },
   "outputs": [],
   "source": [
    "cs_dataset = dataset.map(to_instruction_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQju-HORcoD5",
    "outputId": "351cf386-9967-44f8-a561-2802c1c82429"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'complex_cot', 'response', 'instruction', 'input', 'output'],\n",
       "    num_rows: 47789\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65Q7WloZcp6k",
    "outputId": "cefc203c-50c9-4d61-d760-3ef068c1df4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 1 ---\n",
      "Instruction: Explain the following from a Company Secretary compliance perspective under Indian law\n",
      "Input: Explain the legal provisions relating to biodiversity conservation under the Biological Diversity Act, 2002. How does the National Biodiversity Authority (NBA) regulate access to biological resources in India?\n",
      "Output: **Understanding Biodiversity Conservation in India: An Overview**\n",
      "\n",
      "India has established a robust legal framework to protect its biodiversity, recognizing the importance of biological diversity to ecological health and economic sustainability. The Biological Diversity Act, 2002, is a cornerstone legislation that addresses biodiversity conservation through provisions related to protected areas, conservation measures, and penalizing illegal activities. This act also established the National Biodiversity Authority (NBA) as a regulatory body to oversee biodiversity-related matters.\n",
      "\n",
      "**Role of the National Biodiversity Authority (NBA)**\n",
      "\n",
      "The NBA, established under the Biological Diversity Act, plays a crucial role in regulating access to biological resources. It issues permits, conductsrisk assessments, and enforces compliance with biodiversity laws. The NBA's framework ensures that industries and researchers can access biological resources while safeguarding ecological integrity, emphasizing informed consent and biosecurity.\n",
      "\n",
      "**Recent Legitations Impacting Biodiversity and Environment**\n",
      "\n",
      "In the past five years, several legislations have been introduced to enhance biodiversity and environmental governance. Notable among these is the Climate Change Act, 2021, which integrates biodiversity considerations into climate strategies. Additionally, the Environment Protection Amendment Act of 2020 and state-level regulations have been updated to strengthen environmental protections and promote sustainable practices, reflecting a national commitment to ecological health.\n",
      "\n",
      "**Informed Consent and Biosecurity**\n",
      "\n",
      "Informed consent in environmental governance refers to the process where decision-makers assessments of potential environmental and biosecurity impacts are conducted before granting access to biological resources. This concept ensures that such access is responsible and avoid unintended ecological harm, aligning with biosecurity protocols to protect against biological hazards. It differs from informed consent in medical contexts by prioritizing environmental sustainability.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "The Biological Diversity Act, 2002, provides a comprehensive legal framework for biodiversity conservation in India, supported by the NBA's regulatory efforts. Recent legislations emphasize environmental protection, while informed consent ensures biosecurity in resource access. Together, these elements underscore India's commitment to sustainable biodiversity management and environmental governance.\n",
      "\n",
      "--- Sample 2 ---\n",
      "Instruction: Explain the following from a Company Secretary compliance perspective under Indian law\n",
      "Input: Explain the concept of 'workman' as defined under the Industrial Disputes Act, 1947, and how it applies to a software engineer employed on a contractual basis in Bangalore.\n",
      "Output: The concept of 'workman' under the Industrial Disputes Act, 1947, has evolved over time to include a broader range of professions, particularly in modern industries. In the context of Bangalore, where software engineering is prominent, professionals in this field are often classified as workmen under the Act. This classification is supported by Supreme Court rulings, such as the Bharat screening case, which have emphasized that IT professionals performing tasks akin to manufacturing processes in the IT sector are considered workmen.\n",
      "\n",
      "Key considerations include:\n",
      "\n",
      "1. **Definition Expansion**: The Act's traditional definition of a workman has been interpreted to include software engineers due to the integral role they play in the IT industry, even if theiremployment is contractual.\n",
      "\n",
      "2. **Employment Types**: Contract and casual employees are included. The distinction is more about the nature of the work and the industry's classification rather than the employment type.\n",
      "\n",
      "3. **jurisdictional Considerations**: While the Act's central government Advised jurisdiction, disputes are typically handled by state authorities. In Bangalore, software engineers may be classified as workmen under the Act's provisions.\n",
      "\n",
      "In conclusion, software engineers in Bangalore are recognized as workmen under the Industrial Disputes Act, covering both contractual and casual employees, due to the evolving interpretation of the Act to include modern professions.\n",
      "\n",
      "--- Sample 3 ---\n",
      "Instruction: Explain the following from a Company Secretary compliance perspective under Indian law\n",
      "Input: What is the role of 'Judicial Precedent' in the interpretation of statutes, and how does 'Stare Decisis' affect the process?\n",
      "Output: **Role of Judicial Precedent and Stare Decisis in Interpreting Statutes**\n",
      "\n",
      "1. **Judicial Precedent**: This is the body of prior court decisions used as guidelines for interpreting and applying statutes. Judges refer to these precedents to inform their decisions, especially when a statute's meaning is ambiguous or unclear. Precedent helps maintain consistency and predictability in legal decisions, providing a foundation for future courts to follow similar principles.\n",
      "\n",
      "2. **Stare Decisis**: This principle, meaning \"to stand by what has been decided,\" requires courts to adhere to their own past decisions unless there are compelling reasons to override them. It ensures that legal interpretations remain consistent, reducing unpredictability and uncertainty in the law.\n",
      "\n",
      "3. **Interpretation Process**: Courts do not mechanically apply precedents but engage with both the text of statutes and prior rulings. They reconcile past decisions with current legal texts, deriving principles to inform their interpretations. This balance allows for reasoned application while maintaining legal coherence.\n",
      "\n",
      "4. **Common Law vs. Civil Law Systems**: In common law systems, judicial precedent plays a significant role due to the absence of extensive written codes in some areas. In contrast, civil law systems have detailed statutes, but judicial precedent still aids in clarifying ambiguities or conflicts within statutes.\n",
      "\n",
      "5. **Judicial Activism**: Even in cases where judges might impose their policy beyond a statute's text, they must follow prior precedents unless they justify overruling them. This ensures that decisions remain grounded in legal framework while allowing for necessary legal evolution.\n",
      "\n",
      "6. **Challenges**: While providing consistency, judicial precedent can sometimes lead to outdated or restrictive decisions, hindering legal progress. Courts must adapt to new situations, balancing consistency with the need for legal development.\n",
      "\n",
      "In conclusion, judicial precedent and stare decisis are crucial for maintaining a coherent and predictable legal system. They guide courts in interpreting statutes, ensuring consistency while allowing for reasoned evolution in the law.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    data = cs_dataset[i]\n",
    "    instruction = data[\"instruction\"]\n",
    "    input = data[\"input\"]\n",
    "    output = data[\"output\"]\n",
    "\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(\"Instruction:\", instruction)\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UWoKxNdSc7p4"
   },
   "outputs": [],
   "source": [
    "# Trimming the answers below 2000 chars to save from OOM errors\n",
    "MAX_LEN = 2000\n",
    "\n",
    "def trim_output(example):\n",
    "    example[\"output\"] = example[\"output\"][:MAX_LEN]\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f3574491632f45b2a805c80d1168f808",
      "b4fa38cc4a964827831bc03f640d51c5",
      "4ade69e8fccc40e39d63c2e095d0d206",
      "56c5d2ae093c4b6890c23d9ff742c4a2",
      "14418b67a8484f15bd7443b0ba46bf49",
      "02a9a393f2554088bdbbf1dce2662f1d",
      "2f249d07f34a42909a79a31ed147bed8",
      "e9fcc0f4561343518f41ecfd0b35d24c",
      "7d01bce1463c4514a935b99657906b69",
      "ad19fe93194b416a82c75339cd7d6a1d",
      "442f4c89b16c44eb9b9561ed49758215"
     ]
    },
    "id": "UJWiJuzkeSkv",
    "outputId": "c1197929-3f23-4cf0-b016-bc1049239347"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5c503ca1fb4ca18383d76bff646bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs_dataset = cs_dataset.map(trim_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de7Pvi0FeTDw",
    "outputId": "995ec297-0c48-482c-a944-5764d4592d4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'complex_cot', 'response', 'instruction', 'input', 'output'],\n",
       "    num_rows: 47789\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2Pwd91Dgzm5"
   },
   "source": [
    "Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tRkfd3SwgiYe"
   },
   "outputs": [],
   "source": [
    "columns_remove = [\"prompt\", \"complex_cot\", \"response\"]\n",
    "\n",
    "cs_dataset = cs_dataset.remove_columns(columns_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrroHISYhCMt",
    "outputId": "0f7cc3fc-3056-4272-c770-c96bd537edbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Explain the following from a Company Secretary compliance perspective under Indian law',\n",
       " 'input': 'Explain the legal provisions relating to biodiversity conservation under the Biological Diversity Act, 2002. How does the National Biodiversity Authority (NBA) regulate access to biological resources in India?',\n",
       " 'output': \"**Understanding Biodiversity Conservation in India: An Overview**\\n\\nIndia has established a robust legal framework to protect its biodiversity, recognizing the importance of biological diversity to ecological health and economic sustainability. The Biological Diversity Act, 2002, is a cornerstone legislation that addresses biodiversity conservation through provisions related to protected areas, conservation measures, and penalizing illegal activities. This act also established the National Biodiversity Authority (NBA) as a regulatory body to oversee biodiversity-related matters.\\n\\n**Role of the National Biodiversity Authority (NBA)**\\n\\nThe NBA, established under the Biological Diversity Act, plays a crucial role in regulating access to biological resources. It issues permits, conductsrisk assessments, and enforces compliance with biodiversity laws. The NBA's framework ensures that industries and researchers can access biological resources while safeguarding ecological integrity, emphasizing informed consent and biosecurity.\\n\\n**Recent Legitations Impacting Biodiversity and Environment**\\n\\nIn the past five years, several legislations have been introduced to enhance biodiversity and environmental governance. Notable among these is the Climate Change Act, 2021, which integrates biodiversity considerations into climate strategies. Additionally, the Environment Protection Amendment Act of 2020 and state-level regulations have been updated to strengthen environmental protections and promote sustainable practices, reflecting a national commitment to ecological health.\\n\\n**Informed Consent and Biosecurity**\\n\\nInformed consent in environmental governance refers to the process where decision-makers assessments of potential environmental and biosecurity impacts are conducted before granting access to biological resources. This concept ensures that such access is responsible and avoid unintended ecological harm, aligning with biosecurity protocols to protect against biological hazards\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzinVIJChG0S"
   },
   "source": [
    "Defining a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qgkUrqGQhsT0"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "X3Fxm0GqhDQG"
   },
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "c3fd780a91fc4afaadb6047b7d2c6bef",
      "f9dcfc719ad942dcb189b667e3e795c1",
      "006511decc0a46528da7b0ee6504f9a6",
      "111f8108dc33411a94424555c8f61764",
      "67738e6ae6c4491e96e6240fbde81a88",
      "2a6af08be437470db24d89f1bd29b7d2",
      "635bebfa0b5b4f9eb2dffcc629997509",
      "1e33ef60907b4e3992b18f8fffe58061",
      "9fd8f20f41154a328fa854c230b9e30d",
      "bee727d082874e96ade6c87ad554c0dd",
      "e2ca8236080e4ee9b7377f717663d598",
      "5f48c693a66c489ab58ae973cb154dfb",
      "ebf5ac08ec7b419ebcc607f7ce6ee267",
      "df0d0acfddc3464f9999162bb755135e",
      "67640e581ccc4680aac93c4347f29442",
      "432c9ac09150499db69f3563ad822174",
      "72a8532ee2144122b5d1691868553f0a",
      "23857b0b34044e94a057fd5d79a403b5",
      "02c5a0ccbb554045ad4d06a8c2fe527e",
      "5ce874e636b5431f87e3d87307c0f78a",
      "f25624c9a19a42eabe048d8817de859b",
      "6715faa3e5264951b1f14d71c974dd83",
      "f86b3883a99e498a954335e22e0bbcc7",
      "4dea8d4120cc44f887212dd985eda300",
      "81566870baa148bbb7869d3f60be5a10",
      "1ff1ea50838b4b169014d8358a70cff4",
      "a4f8be4cf6ad4da89fb1259a92802cc6",
      "a07b0b4f63394fe8a30c2ccf09e6a038",
      "ff6deeea5a1a4117b749ee5356c1cd81",
      "3c739c39465a4b8286950aca098f95a4",
      "7f1b07885bcd4ee1a600c25669325380",
      "2f38334b8b96478b8f21429cf231c067",
      "93eaa7cca2434bd292a214b457eb907e",
      "49499c6e2f46442d936807dbbb7a7516",
      "af073d0974ff47fa8c4f83e9c826ddf8",
      "fab2ada1292a4452af59462d2b59f000",
      "1b98a414a7614af48d1a9bba31831c81",
      "97afa5f31efc476982034ac7015ee2a6",
      "004163d810854bcb9525594376c696ab",
      "da43154eeef74b12bf991f7fb0d92bdf",
      "e0cbf4484f3643f79a5281f59e7387c6",
      "e3192a68368043c19680533bab875978",
      "e3b62cec75044a3f8818088418889e1b",
      "5d853302c75e4954b0cb73bdd7d47a17"
     ]
    },
    "id": "bk3_F3dQhrY7",
    "outputId": "633bc87c-8a52-4f33-efaa-1179867634e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5WJGjoljN_l"
   },
   "source": [
    "Formatting the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6Z0vHv2ljMje"
   },
   "outputs": [],
   "source": [
    "def format_prompt(example):\n",
    "    return (\n",
    "        f\"Instruction:\\n{example['instruction']}\\n\\n\"\n",
    "        f\"Input:\\n{example['input']}\\n\\n\"\n",
    "        f\"Response:\\n{example['output']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl4O0QX-iTiV"
   },
   "source": [
    "Mapping the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DNr8iiTjh-9k"
   },
   "outputs": [],
   "source": [
    "# def map_dataset(example) :\n",
    "#   text = format_prompt(example)\n",
    "#   return tokenizer(text,\n",
    "#                    truncation = True,\n",
    "#                    max_length = 1024,\n",
    "#                    return_overflowing_tokens = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NInUmf3jrhf"
   },
   "source": [
    "Applying the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8OYJ9Y61jqVh"
   },
   "outputs": [],
   "source": [
    "# tokenized_cs_dataset = cs_dataset.map(\n",
    "#     map_dataset,\n",
    "#     remove_columns = list(cs_dataset.columns)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0z9_eWLRpGKr",
    "outputId": "707a4a6d-ceda-4ed5-de6c-f44cb697d261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 47789\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOIYIGu3pLH3"
   },
   "source": [
    "Define DataCollatorForLanguageModelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "idPfyKB0pHAn"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3ZHatOILpYyw"
   },
   "outputs": [],
   "source": [
    "# data_collator = DataCollatroForLanguageModelling.from_pretrained(\n",
    "#     tokenizer = tokenizer,\n",
    "#     mlm = False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pprpxJLIpsPY"
   },
   "source": [
    "Define BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fk-i4020qupp",
    "outputId": "688f97b2-7ac7-47a3-d231-49cdeba7c0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: bitsandbytes 0.49.0\n",
      "Uninstalling bitsandbytes-0.49.0:\n",
      "  Successfully uninstalled bitsandbytes-0.49.0\n",
      "Collecting bitsandbytes==0.43.3\n",
      "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torch in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bitsandbytes==0.43.3) (2.7.1+cu118)\n",
      "Requirement already satisfied: numpy in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bitsandbytes==0.43.3) (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (3.6)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->bitsandbytes==0.43.3) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch->bitsandbytes==0.43.3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->torch->bitsandbytes==0.43.3) (3.0.3)\n",
      "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m224.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.3\n",
      "Requirement already satisfied: transformers in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: peft in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.18.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from accelerate) (2.7.1+cu118)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from trl) (4.4.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.1.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n",
      "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Downloading trl-0.26.2-py3-none-any.whl (518 kB)\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.26.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y bitsandbytes\n",
    "!pip install -U bitsandbytes==0.43.3\n",
    "!pip install -U transformers accelerate peft trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "q2SFeR_YpdQ7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ObDUD3ZHpyOz"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqpMo5HLrp1k"
   },
   "source": [
    "Apply BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmFb1JZ-sVJh",
    "outputId": "0f24bf08-87ba-49fa-a425-8f87bddfa76f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.43.3)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bitsandbytes) (2.7.1+cu118)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.6)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Using cached bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.43.3\n",
      "    Uninstalling bitsandbytes-0.43.3:\n",
      "      Successfully uninstalled bitsandbytes-0.43.3\n",
      "Successfully installed bitsandbytes-0.49.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "g9ClNibtqVtf"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "e69459761c7c4d6abb0b31c53e17b25d",
      "e84c86b72dad41358779ef8acfd76fe7",
      "5a7e20494e6e435b886d33fd03fdbd3f",
      "d2decb38b3054e72bc08987ce877c393",
      "753ebf3faae646f8aaf89d17a1037c60",
      "be8c1b2248474fb3b137bb2f3ed3f136",
      "98a7565ef51b44cb838525e3b51497fb",
      "5be4cb6fdf5948b48ca74322346cf10d",
      "8a2f61d4767c4a908ee51597fe9c005d",
      "6f1cc3a8ae3c4a3fa9bc03044472681e",
      "93b6776e827246a8a11afa5fb7dc022c",
      "c30000f0e53d41029f599a5b064c70aa",
      "734af2f1b363475984231c77684d26fd",
      "10d7d5ebdbab418184b269d794f69899",
      "c3be5e44f8a54108b93d9430ac59ec0d",
      "4b1a1e7cee9e4649a1bae4619028c4d1",
      "d5ca926cf3014bb3b02213d19b5174ae",
      "b63f50456dcb463684c64fa82368fcaa",
      "6146b156dc404eb79bf04a31552a3ee8",
      "09d4091708b5489f8d9beccf7ad426e7",
      "40819514217e43feb14aa56ce860a419",
      "5ff9a764a1ee49269e2a10fe5d27f496",
      "788a1ec3cb1f435d9df347bc9a17d3f8",
      "7391b82b0e0a46c5a7dd88b8dbef17b8",
      "4729a4602c6a426baaf30eaadd173b31",
      "2451daf7fb8a45d29f26e920dfe94096",
      "b608a5c66cb24895944921b352c166d0",
      "9f26cf7b742c478098c9a0771ecd4b09",
      "d142c4238fa948de850a0cb2edbd2505",
      "8cabfb911fac489086077605c24d5675",
      "3e85f77bb0db44e59f8bf2ceabcb89d0",
      "90b0e72a7851482aa048ff77e26d20b1",
      "e3f5578fe80c459e8902e52046c298a4",
      "261bdc88ef924173b2228b4ff0f256ed",
      "a02b5fbbad6c4b0883d4fe652a6bd5ff",
      "6892ac3071354196b2855a42a250e060",
      "8cd610e6a63b47cca572f6f996d13aa7",
      "ecdd75856b70440d93555b16b9f0ecde",
      "0cb531b627f64295bf8bbda12af45d78",
      "3bcce06b8b61405da1e0462eac962201",
      "4eec48e6009a4b00a46e193e672dad52",
      "0701cc4ff04b4383b3a54d64d7197430",
      "d5cbea18f5da44779a54e833e2c174c8",
      "4da7bf091f0142cf9719b2b529f47a6a",
      "a8c2a39dca924565aea77d407e9937be",
      "820835573270442f8eca304fac49d44a",
      "05fb6ddb6bfb4293a8acdb4a433ff452",
      "a762068bc11c422196c8fd49c170ccf2",
      "853c4084ccaf4945863f3a26a89a7ccd",
      "552eca8cdcad4c798467a20a8ad75dee",
      "5c86bb71d48b4b1a84d33ff1ab77b12c",
      "143b764662604e8fb3a59a82325ad3fe",
      "3ced686043734cdea3b76bde6d07abce",
      "d478e7e548144f75b1f399b5719c3ffc",
      "8e7278d17bf740b08dec718852047e5a",
      "a8d45a7ebd8a4c41baffe0e11fd89cd7",
      "6e6ba79d3df845678d2f9f4007f8c1eb",
      "03774901f5654c6d90361bbd9f959d22",
      "38940f0a5bd84c06b9c34dd85f820ff4",
      "4165959fc733406fbeba6ab44be23f9d",
      "51628f36f98c4e0eb9aa79c053f007e6",
      "2a8b349d5e644697b27d504e6325f31c",
      "e2b2723b0e9b402981efeeb5c03dbe71",
      "713756b449e1455d8a29ac21125c6644",
      "f4b7a8a515174420a343fc1669f4c274",
      "9197016531574c908da6ae2f020019e4",
      "1c8dc4a9c3cf4036a35fed424aed2b72",
      "fb7167302776440fa94dfe4f2466cabc",
      "0418b3cc6dfd445cac9b314497c24441",
      "9e62e9f7e1d14c8bbaa3c71ef6ad52fe",
      "caa6f7cd722e4d35a552c1b038126d15",
      "58c98d5c77124706999903e8fc7cfb76",
      "04a23499a28e4563ad703d17223fd883",
      "fb45f6fee56b47ad92d8e0d34b20dadd",
      "95489b313d1e4390ac4db0ea57c134e7",
      "29469aac113848488ab60bbec67454dd",
      "c189b34d3d8c49d284fb6a2ac066ae80"
     ]
    },
    "id": "PhmgldZMrvRk",
    "outputId": "86939813-cc41-40c2-8a54-35b1345253ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b0ac1c15a14e598ab01c838fd6dbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPpSrS0ftjg9"
   },
   "source": [
    "Prepare model for K bit training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "WuyZMVAXsQ8c"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "gQJ0aLWOtc_t"
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjQ8DH5SuGf1",
    "outputId": "863e6c77-0b52-48db-fb53-acf706bec96b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.28.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.29.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.30.mlp.down_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.v_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.self_attn.o_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.gate_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.up_proj.lora_magnitude_vector\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.base_layer\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_dropout\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_dropout.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_A.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_B.default\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_embedding_A\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_embedding_B\n",
      "base_model.model.base_model.model.base_model.model.model.layers.31.mlp.down_proj.lora_magnitude_vector\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules() :\n",
    "  if \"proj\" in name.lower() :\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX_jf0wKtlrx"
   },
   "source": [
    "Define LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "B5ny0lSPt4u3"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Y5b2_WFutn_v"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r = 16,\n",
    "    lora_alpha = 32,\n",
    "    # target_modules = [\"self_attn.q_proj\", \"self_attn.k_proj\", \"self_attn.v_proj\", \"self_attn.o_proj\"],\n",
    "    target_modules = \"all-linear\",\n",
    "    lora_dropout = 0.1,\n",
    "    bias = \"none\",\n",
    "    task_type = \"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnnSmfKnwP2h"
   },
   "source": [
    "Apply LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COYHN94My29M",
    "outputId": "3f6f4bf5-47c9-435d-93c6-d46816ab4467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'peft.peft_model.PeftModelForCausalLM'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ivcjwYxbtnoe"
   },
   "outputs": [],
   "source": [
    "from peft import get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ULHXEs1twUoi"
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0pJ8y4_wc9o",
    "outputId": "5a47c258-437c-4dbd-809f-c04ee8b663a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 42,520,576 || all params: 7,284,252,672 || trainable%: 0.5837\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_jE8sDd1bNS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySWFT6U51YVK"
   },
   "source": [
    "Total Trainable Parameters = 0.28875637 % and LoRA adapters are successfully attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2bvmZo906kF",
    "outputId": "3e568044-81eb-467d-a232-0e2449c6fbdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2887563792882719"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20971520/7262703616)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsZSUdlS1g8G"
   },
   "source": [
    "Training Config for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "zgHM02Hd1Sp2"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "w8xq4T2i1nvr"
   },
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir = \"./cs_lora_output_model\",\n",
    "\n",
    "#     # Training Hyperparameter\n",
    "#     num_train_epochs = 5,\n",
    "#     per_device_train_batch_size = 1,\n",
    "#     per_device_eval_batch_size = 1,\n",
    "#     gradient_accumulation_steps = 4,\n",
    "\n",
    "#     # Optimization\n",
    "#     learning_rate = 2e-4,\n",
    "#     lr_scheduler_type = \"cosine\",\n",
    "#     warmup_ratio = 0.05,\n",
    "#     weight_decay = 0.01,\n",
    "\n",
    "#     # Model Optimization\n",
    "#     gradient_checkpointing = False,\n",
    "#     optim = \"paged_adamw_8bit\",\n",
    "#     max_grad_norm = 0.3,\n",
    "\n",
    "#     # Logging\n",
    "#     logging_dir = \"./logs\",\n",
    "#     logging_steps = 100,\n",
    "\n",
    "#     # Evaluation\n",
    "#     eval_strategy = \"steps\",\n",
    "#     eval_steps = 100,\n",
    "#     save_strategy = \"steps\",\n",
    "#     save_steps = 100,\n",
    "#     save_total_limit = 2,\n",
    "\n",
    "#     # Performance\n",
    "#     fp16 = True,\n",
    "#     report_to = \"none\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-8lR3Zw38JB"
   },
   "source": [
    "Applying training arguments to SFT trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ESf9Z7nz1xoX"
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from trl import SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "5829c577198240f9840cd19781f95ac0",
      "9968dc55f4b54914879a2a2530ba145e",
      "5d1e321641a1427997ff3c73d15f97cc",
      "1c1c90b4558d4b07aca97113a321489e",
      "0cf8122cdacd44159c10200d95739ac7",
      "92b34371890e481b903b37a2136914e3",
      "7c2f0f86d3fd4a409b16dbc1f2c8d2ba",
      "1ffd9c19f7bb4162b337e1ebf7fc1bb7",
      "9e4486343356428f93d801446e1c0075",
      "f960e5f011e0483a99394c9a6100c64f",
      "f5b3ac9d591148758489b6def986ac59"
     ]
    },
    "id": "6xVC9Kwa7oHg",
    "outputId": "2a45d95f-8d98-4ad9-8767-2488b4773509"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264f108feec14d4cbab7928481e27bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_text(example):\n",
    "    return {\n",
    "        \"text\": (\n",
    "            f\"Instruction:\\n{example['instruction']}\\n\\n\"\n",
    "            f\"Input:\\n{example['input']}\\n\\n\"\n",
    "            f\"Response:\\n{example['output']}\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "cs_dataset = cs_dataset.map(build_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynfQ3E7-9vho",
    "outputId": "0099cccd-ac25-4148-c7ed-e0252e1256b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 47789\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "a0jfA9ra4BDd"
   },
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    # Output\n",
    "    output_dir = \"./cs_lora_output_model\",\n",
    "\n",
    "    dataset_text_field = \"text\",\n",
    "\n",
    "    # Training Hyperparameters\n",
    "    num_train_epochs = 2,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 1,\n",
    "    gradient_accumulation_steps = 8,\n",
    "\n",
    "    # Optimization\n",
    "    learning_rate = 5e-5,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    warmup_ratio = 0.1,\n",
    "    weight_decay = 0.01,\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "\n",
    "    # Memory Optimization\n",
    "    gradient_checkpointing = True,\n",
    "    gradient_checkpointing_kwargs = {\"use_reentrant\": False},\n",
    "    max_grad_norm = 1.0,\n",
    "\n",
    "    # Logging\n",
    "    logging_dir = \"./logs\",\n",
    "    logging_steps = 100,\n",
    "\n",
    "    # Evaluation\n",
    "    eval_strategy = \"no\",\n",
    "    # eval_strategy = \"steps\",\n",
    "    # eval_steps = 100,\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps = 500,\n",
    "    save_total_limit = 50,\n",
    "\n",
    "    # Performance\n",
    "    bf16 = True,\n",
    "    report_to = \"none\",\n",
    "\n",
    "    # SFT specific settings\n",
    "    max_length = 1024,\n",
    "    packing = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "5c507246ba1241f5b56ae6cf951ebe9a",
      "dd10fbeb89994271838ae05e88133ec6",
      "44078e74339e487a9d8553a27d78c942",
      "8ec1fc4ab6954d8da68b1e2e73abb149",
      "1fccb39eac1f4b67a98d6aa2afebb00b",
      "ecade8245d2d4286bec02891cf2aa663",
      "5f5c2641cc2e4f769f1ed1dcf3512a76",
      "953d40aa0f1c498d89b4140bf2ee8e87",
      "63a85ed0dc674ce5b620e50acdd165a9",
      "1787d1eaa2a3494bac5a55911eab1ac9",
      "775d5e3b8ddd4efba45a087792fd20ce",
      "1cbf672d86ee41f4a61b6c7819807300",
      "f3528f55f4cc4423a152b68acb05bc23",
      "fcba1ff6aaeb465c9cda02bc7dde0692",
      "e98d34abe8a147c9a586b48ef2dd8536",
      "a2c7b4151ba342fb9faf2bbb2c25d216",
      "2904d5798e82499ab2c78df46979aba3",
      "775815fabf6f4c308ae82bcdd232e236",
      "43a5333d499f4541908e0773a668d16e",
      "a3476e8392764a83a3241d553c7a49f0",
      "6c5daf8b18b64a5c927ad836159ee610",
      "b4f3ac777d334459aa15db6f513ab516",
      "ecd267e13bc64adbab9244502a01a088",
      "e95150bed40f410786bf37574493b6e2",
      "e7e206a46c1f4ba38a84012813cd2d75",
      "2b7908894f9e4011aaf12e5d59b20eeb",
      "875de1949ab34611a345d19eb1e47d20",
      "b5f8423cf5e943f6a038834bf432e9f5",
      "14da0ed71f0f472785b80fdfcd742a66",
      "5d1add9086ed469ba6050c78b2494575",
      "f08e4d8625b54b778519d6d44da004cc",
      "fb3b57f67fa64a7a9f8748f53abd58e3",
      "4c91aa5ec08c4043a25276b18e08aadb"
     ]
    },
    "id": "v6hcw0ib5WPW",
    "outputId": "f525fc09-845a-479b-d6d2-30af930e6eb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d6515be8d24511a036f2882972638a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/47789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b632ac8175ed4cd2a176b2c063172a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/47789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b15eda4e6d4260b128ee52b3a680e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/47789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    args = sft_config,\n",
    "    train_dataset = cs_dataset,\n",
    "    processing_class = tokenizer\n",
    "    # formatting_func = format_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYi0nzhE-DKR"
   },
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "yHfMM5Ee52fL",
    "outputId": "aa3957cc-57c8-470e-fa28-db2ff3687e4f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2428' max='11948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2428/11948 2:02:36 < 8:01:06, 0.33 it/s, Epoch 0.41/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.128400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.988500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.996500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.986700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>4.429800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1248233.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>379688.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>133192356986.880005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2672\u001b[0m )\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2680\u001b[0m ):\n\u001b[1;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:1245\u001b[0m, in \u001b[0;36mSFTTrainer.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_activation_offload_context:\n\u001b[0;32m-> 1245\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/trainer.py:4020\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   4019\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4020\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   4023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4024\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4025\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   4026\u001b[0m ):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:1153\u001b[0m, in \u001b[0;36mSFTTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_token_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_token_scaling\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mloss_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1153\u001b[0m (loss, outputs) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;66;03m# Compute entropy\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_liger_kernel:  \u001b[38;5;66;03m# liger doesn't return logits\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/trainer.py:4110\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   4109\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 4110\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   4112\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   4113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/peft/peft_model.py:1923\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1922\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1934\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:308\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/utils/generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:433\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m    415\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[1;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/utils/generic.py:1072\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1072\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:369\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(hidden_states, position_ids)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers]:\n\u001b[0;32m--> 369\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[1;32m    381\u001b[0m     last_hidden_state\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    382\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/modeling_layers.py:93\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gradient_checkpointing_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/_compile.py:51\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     49\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback))\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/utils/checkpoint.py:495\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Runs pre-forward logic\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[0;32m--> 495\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Runs post-forward logic\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:231\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m hidden_states, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:182\u001b[0m, in \u001b[0;36mMistralAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m attention_interface(\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    171\u001b[0m     query_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    181\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 182\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:547\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_layer(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# As per Tim Dettmers, for 4bit, we need to defensively clone here.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;66;03m# The reason is that in some cases, an error can occur that backprop\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# does not work on a manipulated view. This issue may be solved with\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# newer PyTorch versions but this would need extensive testing to be\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;66;03m# sure.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:555\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    552\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    553\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(quant_state, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpacking_format_for_cpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mt()\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:401\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul4Bit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:315\u001b[0m, in \u001b[0;36mMatMul4Bit.forward\u001b[0;34m(ctx, A, B, out, bias, quant_state)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(A\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m B_shape[:\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# 1. Dequantize\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# 2. MatmulnN\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(A, \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdequantize_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(A\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mt(), bias)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# 3. Save state\u001b[39;00m\n\u001b[1;32m    318\u001b[0m ctx\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m quant_state\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/functional.py:1004\u001b[0m, in \u001b[0;36mdequantize_4bit\u001b[0;34m(A, quant_state, absmax, out, blocksize, quant_type)\u001b[0m\n\u001b[1;32m    994\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mbitsandbytes\u001b[38;5;241m.\u001b[39mdequantize_4bit\u001b[38;5;241m.\u001b[39mdefault(\n\u001b[1;32m    995\u001b[0m         A,\n\u001b[1;32m    996\u001b[0m         absmax,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         quant_state\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m   1001\u001b[0m     )\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# is transposed, transpose back\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "-cGr_C50_H_-"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "uNcA-ygiG-q7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e19944f16f4be6b0fa54bc62492a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    \"./cs_lora_output_model/checkpoint-1500\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "l2nbQU0OG-q7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2cf8a53935403a971e4fe407700fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): MistralRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"   # same base model you trained on\n",
    "checkpoint_path = \"./cs_lora_output_model/checkpoint-1500\"\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Base model (quantized)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load LoRA checkpoint\n",
    "model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    checkpoint_path\n",
    ")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "KkHhQSLaG-q8"
   },
   "outputs": [],
   "source": [
    "# same output formatter as during training\n",
    "\n",
    "def build_prompt(instruction, input_text=\"\"):\n",
    "    if input_text.strip():\n",
    "        return (\n",
    "            f\"Instruction:\\n{instruction}\\n\\n\"\n",
    "            f\"Input:\\n{input_text}\\n\\n\"\n",
    "            f\"Response:\\n\"\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            f\"Instruction:\\n{instruction}\\n\\n\"\n",
    "            f\"Response:\\n\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8vBjiQsEG-q9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qenSH5v2G-q-"
   },
   "source": [
    "#### Test the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "JR030mA2G-q-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "A buyer signs a contract under coercion. Step by step, explain whether the contract is enforceable.\n",
      "\n",
      "Response:\n",
      "The contract is not enforceable. The contract was signed under duress. Duress is defined as “the use of force or threats to compel another person to act against his will.” Restatement (Second) of Contracts § 176(2). In this case, the seller threatened to kill the buyer if he did not sign the contract. This threat constitutes duress because it is an illegal threat that would cause a reasonable person to act against his will. See id. at § 176 cmt. b. Because the buyer acted under duress, the contract is unenforceable. Id. at § 178.\n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt(\n",
    "    # \"Explain the role and responsibilities of a Company Secretary under the Companies Act, 2013.\"\n",
    "    # \"Explain the concept of consideration in contract law with an example.\"\n",
    "    # \"Can a contract be valid without consideration? Explain with case reasoning.\"\n",
    "    \"A buyer signs a contract under coercion. Step by step, explain whether the contract is enforceable.\"\n",
    ")\n",
    "\n",
    "outputs = text_generator(\n",
    "    prompt,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    repetition_penalty=1.1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "OrHC62gZG-q_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The contract is not enforceable. The contract was signed under duress. Duress is defined as “the use of force or threats to compel another person to act against his will.” Restatement (Second) of Contracts § 176(2). In this case, the seller threatened to kill the buyer if he did not sign the contract. This threat constitutes duress because it is an illegal threat that would cause a reasonable person to act against his will. See id. at § 176 cmt. b. Because the buyer acted under duress, the contract is unenforceable. Id. at § 178.\n"
     ]
    }
   ],
   "source": [
    "def extract_response(generated_text):\n",
    "    return generated_text.split(\"Response:\")[-1].strip()\n",
    "\n",
    "final_answer = extract_response(outputs[0][\"generated_text\"])\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.52.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<7,>=4.0 (from streamlit)\n",
      "  Downloading altair-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (6.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (8.3.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (12.0.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (4.23.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (22.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (2.32.5)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (4.15.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
      "Collecting narwhals>=1.27.1 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.52.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-6.0.0-py3-none-any.whl (795 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m795.4/795.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m216.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading narwhals-2.14.0-py3-none-any.whl (430 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, narwhals, blinker, pydeck, gitdb, gitpython, altair, streamlit\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [streamlit]11\u001b[0m [streamlit]\n",
      "\u001b[1A\u001b[2KSuccessfully installed altair-6.0.0 blinker-1.9.0 gitdb-4.0.12 gitpython-3.1.45 narwhals-2.14.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.52.2 tenacity-9.1.2 toml-0.10.2 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.96.0.107:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://204.12.163.123:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_http.py\u001b[0m:402 in hf_raise_for_status                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m399 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m>         If request failed for a reason not listed above.\u001b[0m                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m400 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m402 \u001b[2m│   │   \u001b[0mresponse.raise_for_status()                                            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m403 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m HTTPError \u001b[94mas\u001b[0m e:                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   │   \u001b[0merror_code = response.headers.get(\u001b[33m\"\u001b[0m\u001b[33mX-Error-Code\u001b[0m\u001b[33m\"\u001b[0m)                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   │   \u001b[0merror_message = response.headers.get(\u001b[33m\"\u001b[0m\u001b[33mX-Error-Message\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/requests/\u001b[0m\u001b[1mmodels.p\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1my\u001b[0m:1026 in raise_for_status                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1023 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1024 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1025 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m http_error_msg:                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1026 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m HTTPError(http_error_msg, response=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m)\u001b[0m                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1027 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1028 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mclose\u001b[0m(\u001b[96mself\u001b[0m):                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1029 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Releases the connection back to the pool. Once this method has bee\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mHTTPError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error: Unauthorized for url: \n",
      "\u001b[4;94mhttps://huggingface.co/your-base-model-name/resolve/main/tokenizer_config.json\u001b[0m\n",
      "\n",
      "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:479 in cached_files                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 476 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 477 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(full_filenames) == \u001b[94m1\u001b[0m:                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 478 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# This is slightly better for only 1 file\u001b[0m                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 479 \u001b[2m│   │   │   \u001b[0mhf_hub_download(                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpath_or_repo_id,                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfilenames[\u001b[94m0\u001b[0m],                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 482 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:114 in _inner_fn                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, ha \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m117 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1007 in hf_hub_download                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1004 \u001b[0m\u001b[2m│   │   │   \u001b[0mlocal_files_only=local_files_only,                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1005 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1006 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1007 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4m_hf_hub_download_to_cache_dir(\u001b[0m                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1008 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;2;4m# Destination\u001b[0m                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1009 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mcache_dir=cache_dir,\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1010 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;2;4m# File info\u001b[0m                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1114 in _hf_hub_download_to_cache_dir                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1111 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m pointer_path                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1112 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1113 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Otherwise, raise appropriate error\u001b[0m                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1114 \u001b[2m│   │   \u001b[0m\u001b[1;4m_raise_on_head_call_error(head_call_error, force_download, local_file\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1115 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# From now on, etag, commit_hash, url and size are not None.\u001b[0m              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m etag \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33metag must have been retrieved from server\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1655 in _raise_on_head_call_error                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1652 \u001b[0m\u001b[2m│   \u001b[0m):                                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Repo not found or gated => let's raise the actual error\u001b[0m             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Unauthorized => likely a token issue => let's raise the actual erro\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1655 \u001b[2m│   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m head_call_error\u001b[0m                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1656 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1657 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Otherwise: most likely a connection issue or Hub downtime => let's \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1658 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m LocalEntryNotFoundError(                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1543 in _get_metadata_or_catch_error                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m local_files_only:                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1543 \u001b[2m│   │   │   │   \u001b[0mmetadata = get_hf_file_metadata(                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1544 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0murl=url, proxies=proxies, timeout=etag_timeout, headers=h \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1545 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1546 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m EntryNotFoundError \u001b[94mas\u001b[0m http_error:                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:114 in _inner_fn                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, ha \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m117 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1460 in get_hf_file_metadata                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1457 \u001b[0m\u001b[2m│   \u001b[0mhf_headers[\u001b[33m\"\u001b[0m\u001b[33mAccept-Encoding\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[33m\"\u001b[0m\u001b[33midentity\u001b[0m\u001b[33m\"\u001b[0m  \u001b[2m# prevent any compression => \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1458 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1459 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Retrieve metadata\u001b[0m                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1460 \u001b[2m│   \u001b[0mr = \u001b[1;4m_request_wrapper(\u001b[0m                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1461 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mmethod=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mHEAD\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m,\u001b[0m                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1462 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4murl=url,\u001b[0m                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1463 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mheaders=hf_headers,\u001b[0m                                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:283 in _request_wrapper                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 280 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 281 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Recursively follow relative redirects\u001b[0m                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 282 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m follow_relative_redirects:                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 283 \u001b[2m│   │   \u001b[0mresponse = \u001b[1;4m_request_wrapper(\u001b[0m                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 284 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mmethod=method,\u001b[0m                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 285 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4murl=url,\u001b[0m                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 286 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mfollow_relative_redirects=\u001b[0m\u001b[1;4;94mFalse\u001b[0m\u001b[1;4m,\u001b[0m                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:307 in _request_wrapper                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 304 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 305 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Perform request and return if status_code is not in the retry list.\u001b[0m     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 306 \u001b[0m\u001b[2m│   \u001b[0mresponse = http_backoff(method=method, url=url, **params)                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 307 \u001b[2m│   \u001b[0m\u001b[1;4mhf_raise_for_status(response)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m response                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 309 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 310 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_http.py\u001b[0m:452 in hf_raise_for_status                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m449 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m make sure you are authenticated. For more details, see\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m450 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[0m\u001b[33m\"\u001b[0m  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m451 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m452 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m _format(RepositoryNotFoundError, message, response) \u001b[0m\u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96me\u001b[0m   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m453 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m454 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m response.status_code == \u001b[94m400\u001b[0m:                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m455 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage = (                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mRepositoryNotFoundError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error. \u001b[1m(\u001b[0mRequest ID: \n",
      "\u001b[33mRoot\u001b[0m=\u001b[1;36m1\u001b[0m-6952553d-24d437832203d78b77f5cd97;\u001b[93m96923e35-3727-4044-8b4c-c50c340c4d94\u001b[0m\u001b[1m)\u001b[0m\n",
      "\n",
      "Repository Not Found for url: \n",
      "\u001b[4;94mhttps://huggingface.co/your-base-model-name/resolve/main/tokenizer_config.json.\u001b[0m\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated. \n",
      "For more details, see \u001b[4;94mhttps://huggingface.co/docs/huggingface_hub/authentication\u001b[0m\n",
      "Invalid username or password.\n",
      "\n",
      "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mexec_code.py\u001b[0m:129 in exec_func_with_error_handling                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mscript_runner.py\u001b[0m:671 in code_to_exec                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:108 in <module>                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0mmodel.eval()                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer, model                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m107 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m108 tokenizer, model = \u001b[1;4mload_model()\u001b[0m                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m109 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m# -------------------------------\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m# Prompt Input\u001b[0m                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:228 in __call__                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:270 in _get_or_create_cached_value                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:329 in _handle_cache_miss                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:98 in load_model                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m# -------------------------------\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 96 \u001b[0m\u001b[1;95m@st\u001b[0m.cache_resource                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 97 \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mload_model\u001b[0m():                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 98 \u001b[2m│   \u001b[0mtokenizer = \u001b[1;4mAutoTokenizer.from_pretrained(\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33myour-base-model-name\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m)\u001b[0m          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   \u001b[0mmodel = AutoModelForCausalLM.from_pretrained(                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33myour-base-model-name\u001b[0m\u001b[33m\"\u001b[0m,                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   \u001b[0mdevice_map=\u001b[33m\"\u001b[0m\u001b[33mauto\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/mode\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mls/auto/\u001b[0m\u001b[1mtokenization_auto.py\u001b[0m:1089 in from_pretrained                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1086 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer_class.from_pretrained(pretrained_model_name_or_p \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1087 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1088 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Next, let's try to use the tokenizer_config file to get the tokeniz\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1089 \u001b[2m│   │   \u001b[0mtokenizer_config = \u001b[1;4mget_tokenizer_config(pretrained_model_name_or_path\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1090 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m tokenizer_config:                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1091 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = tokenizer_config[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1092 \u001b[0m\u001b[2m│   │   \u001b[0mconfig_tokenizer_class = tokenizer_config.get(\u001b[33m\"\u001b[0m\u001b[33mtokenizer_class\u001b[0m\u001b[33m\"\u001b[0m)      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/mode\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mls/auto/\u001b[0m\u001b[1mtokenization_auto.py\u001b[0m:921 in get_tokenizer_config                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 918 \u001b[0m\u001b[2m│   │   \u001b[0mtoken = use_auth_token                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 919 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 920 \u001b[0m\u001b[2m│   \u001b[0mcommit_hash = kwargs.get(\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m)                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 921 \u001b[2m│   \u001b[0mresolved_config_file = \u001b[1;4mcached_file(\u001b[0m                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 922 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mpretrained_model_name_or_path,\u001b[0m                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 923 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mTOKENIZER_CONFIG_FILE,\u001b[0m                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 924 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mcache_dir=cache_dir,\u001b[0m                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:322 in cached_file                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 319 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mmodel_weights_file = cached_file(\"google-bert/bert-base-uncased\", \"pytorc\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 320 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m```\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 321 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 322 \u001b[2m│   \u001b[0mfile = \u001b[1;4mcached_files(path_or_repo_id=path_or_repo_id, filenames=[filename]\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 323 \u001b[0m\u001b[2m│   \u001b[0mfile = file[\u001b[94m0\u001b[0m] \u001b[94mif\u001b[0m file \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m file                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 324 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m file                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 325 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:511 in cached_files                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 508 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 509 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# We cannot recover from them\u001b[0m                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 510 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(e, RepositoryNotFoundError) \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(e, Gated \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 511 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mOSError\u001b[0m\u001b[1;4m(\u001b[0m                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 512 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4mpath_or_repo_id\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m is not a local folder and is not a valid \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 513 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mlisted on \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mhttps://huggingface.co/models\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m\\n\u001b[0m\u001b[1;4;33mIf this is a priv\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 514 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mhaving permission to this repo either by logging in with `hf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mOSError: \u001b[0myour-base-model-name is not a local folder and is not a valid model identifier \n",
      "listed on \u001b[32m'https://huggingface.co/models'\u001b[0m\n",
      "If this is a private repository, make sure to pass a token having permission to this \n",
      "repo either by logging in with `hf auth login` or by passing `\u001b[33mtoken\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95myour_token\u001b[0m\u001b[1m>\u001b[0m`\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_http.py\u001b[0m:402 in hf_raise_for_status                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m399 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m>         If request failed for a reason not listed above.\u001b[0m                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m400 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m402 \u001b[2m│   │   \u001b[0mresponse.raise_for_status()                                            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m403 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m HTTPError \u001b[94mas\u001b[0m e:                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   │   \u001b[0merror_code = response.headers.get(\u001b[33m\"\u001b[0m\u001b[33mX-Error-Code\u001b[0m\u001b[33m\"\u001b[0m)                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   │   \u001b[0merror_message = response.headers.get(\u001b[33m\"\u001b[0m\u001b[33mX-Error-Message\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/requests/\u001b[0m\u001b[1mmodels.p\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1my\u001b[0m:1026 in raise_for_status                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1023 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1024 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1025 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m http_error_msg:                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1026 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m HTTPError(http_error_msg, response=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m)\u001b[0m                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1027 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1028 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mclose\u001b[0m(\u001b[96mself\u001b[0m):                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1029 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Releases the connection back to the pool. Once this method has bee\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mHTTPError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error: Unauthorized for url: \n",
      "\u001b[4;94mhttps://huggingface.co/your-base-model-name/resolve/main/tokenizer_config.json\u001b[0m\n",
      "\n",
      "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:479 in cached_files                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 476 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 477 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(full_filenames) == \u001b[94m1\u001b[0m:                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 478 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# This is slightly better for only 1 file\u001b[0m                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 479 \u001b[2m│   │   │   \u001b[0mhf_hub_download(                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpath_or_repo_id,                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfilenames[\u001b[94m0\u001b[0m],                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 482 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:114 in _inner_fn                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, ha \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m117 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1007 in hf_hub_download                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1004 \u001b[0m\u001b[2m│   │   │   \u001b[0mlocal_files_only=local_files_only,                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1005 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1006 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1007 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4m_hf_hub_download_to_cache_dir(\u001b[0m                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1008 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;2;4m# Destination\u001b[0m                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1009 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mcache_dir=cache_dir,\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1010 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;2;4m# File info\u001b[0m                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1114 in _hf_hub_download_to_cache_dir                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1111 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m pointer_path                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1112 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1113 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Otherwise, raise appropriate error\u001b[0m                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1114 \u001b[2m│   │   \u001b[0m\u001b[1;4m_raise_on_head_call_error(head_call_error, force_download, local_file\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1115 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# From now on, etag, commit_hash, url and size are not None.\u001b[0m              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m etag \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33metag must have been retrieved from server\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1655 in _raise_on_head_call_error                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1652 \u001b[0m\u001b[2m│   \u001b[0m):                                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Repo not found or gated => let's raise the actual error\u001b[0m             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Unauthorized => likely a token issue => let's raise the actual erro\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1655 \u001b[2m│   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m head_call_error\u001b[0m                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1656 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1657 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Otherwise: most likely a connection issue or Hub downtime => let's \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1658 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m LocalEntryNotFoundError(                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1543 in _get_metadata_or_catch_error                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m local_files_only:                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1543 \u001b[2m│   │   │   │   \u001b[0mmetadata = get_hf_file_metadata(                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1544 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0murl=url, proxies=proxies, timeout=etag_timeout, headers=h \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1545 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1546 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m EntryNotFoundError \u001b[94mas\u001b[0m http_error:                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:114 in _inner_fn                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, ha \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m117 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1460 in get_hf_file_metadata                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1457 \u001b[0m\u001b[2m│   \u001b[0mhf_headers[\u001b[33m\"\u001b[0m\u001b[33mAccept-Encoding\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[33m\"\u001b[0m\u001b[33midentity\u001b[0m\u001b[33m\"\u001b[0m  \u001b[2m# prevent any compression => \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1458 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1459 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Retrieve metadata\u001b[0m                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1460 \u001b[2m│   \u001b[0mr = \u001b[1;4m_request_wrapper(\u001b[0m                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1461 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mmethod=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mHEAD\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m,\u001b[0m                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1462 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4murl=url,\u001b[0m                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1463 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mheaders=hf_headers,\u001b[0m                                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:283 in _request_wrapper                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 280 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 281 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Recursively follow relative redirects\u001b[0m                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 282 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m follow_relative_redirects:                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 283 \u001b[2m│   │   \u001b[0mresponse = \u001b[1;4m_request_wrapper(\u001b[0m                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 284 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mmethod=method,\u001b[0m                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 285 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4murl=url,\u001b[0m                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 286 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mfollow_relative_redirects=\u001b[0m\u001b[1;4;94mFalse\u001b[0m\u001b[1;4m,\u001b[0m                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:307 in _request_wrapper                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 304 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 305 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Perform request and return if status_code is not in the retry list.\u001b[0m     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 306 \u001b[0m\u001b[2m│   \u001b[0mresponse = http_backoff(method=method, url=url, **params)                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 307 \u001b[2m│   \u001b[0m\u001b[1;4mhf_raise_for_status(response)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m response                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 309 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 310 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_http.py\u001b[0m:452 in hf_raise_for_status                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m449 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m make sure you are authenticated. For more details, see\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m450 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[0m\u001b[33m\"\u001b[0m  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m451 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m452 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m _format(RepositoryNotFoundError, message, response) \u001b[0m\u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96me\u001b[0m   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m453 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m454 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m response.status_code == \u001b[94m400\u001b[0m:                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m455 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage = (                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mRepositoryNotFoundError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error. \u001b[1m(\u001b[0mRequest ID: \n",
      "\u001b[33mRoot\u001b[0m=\u001b[1;36m1\u001b[0m-\u001b[1;36m69525540\u001b[0m-09869f353852c729135f7944;\u001b[93mbc10124f-b22c-4c63-8b5e-648bb3ed9b2b\u001b[0m\u001b[1m)\u001b[0m\n",
      "\n",
      "Repository Not Found for url: \n",
      "\u001b[4;94mhttps://huggingface.co/your-base-model-name/resolve/main/tokenizer_config.json.\u001b[0m\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated. \n",
      "For more details, see \u001b[4;94mhttps://huggingface.co/docs/huggingface_hub/authentication\u001b[0m\n",
      "Invalid username or password.\n",
      "\n",
      "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mexec_code.py\u001b[0m:129 in exec_func_with_error_handling                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mscript_runner.py\u001b[0m:671 in code_to_exec                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:108 in <module>                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0mmodel.eval()                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer, model                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m107 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m108 tokenizer, model = \u001b[1;4mload_model()\u001b[0m                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m109 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m# -------------------------------\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m# Prompt Input\u001b[0m                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:228 in __call__                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:270 in _get_or_create_cached_value                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:329 in _handle_cache_miss                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:98 in load_model                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m# -------------------------------\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 96 \u001b[0m\u001b[1;95m@st\u001b[0m.cache_resource                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 97 \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mload_model\u001b[0m():                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 98 \u001b[2m│   \u001b[0mtokenizer = \u001b[1;4mAutoTokenizer.from_pretrained(\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33myour-base-model-name\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m)\u001b[0m          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   \u001b[0mmodel = AutoModelForCausalLM.from_pretrained(                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33myour-base-model-name\u001b[0m\u001b[33m\"\u001b[0m,                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   \u001b[0mdevice_map=\u001b[33m\"\u001b[0m\u001b[33mauto\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/mode\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mls/auto/\u001b[0m\u001b[1mtokenization_auto.py\u001b[0m:1089 in from_pretrained                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1086 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer_class.from_pretrained(pretrained_model_name_or_p \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1087 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1088 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Next, let's try to use the tokenizer_config file to get the tokeniz\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1089 \u001b[2m│   │   \u001b[0mtokenizer_config = \u001b[1;4mget_tokenizer_config(pretrained_model_name_or_path\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1090 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m tokenizer_config:                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1091 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = tokenizer_config[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1092 \u001b[0m\u001b[2m│   │   \u001b[0mconfig_tokenizer_class = tokenizer_config.get(\u001b[33m\"\u001b[0m\u001b[33mtokenizer_class\u001b[0m\u001b[33m\"\u001b[0m)      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/mode\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mls/auto/\u001b[0m\u001b[1mtokenization_auto.py\u001b[0m:921 in get_tokenizer_config                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 918 \u001b[0m\u001b[2m│   │   \u001b[0mtoken = use_auth_token                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 919 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 920 \u001b[0m\u001b[2m│   \u001b[0mcommit_hash = kwargs.get(\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m)                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 921 \u001b[2m│   \u001b[0mresolved_config_file = \u001b[1;4mcached_file(\u001b[0m                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 922 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mpretrained_model_name_or_path,\u001b[0m                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 923 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mTOKENIZER_CONFIG_FILE,\u001b[0m                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 924 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mcache_dir=cache_dir,\u001b[0m                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:322 in cached_file                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 319 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mmodel_weights_file = cached_file(\"google-bert/bert-base-uncased\", \"pytorc\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 320 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m```\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 321 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 322 \u001b[2m│   \u001b[0mfile = \u001b[1;4mcached_files(path_or_repo_id=path_or_repo_id, filenames=[filename]\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 323 \u001b[0m\u001b[2m│   \u001b[0mfile = file[\u001b[94m0\u001b[0m] \u001b[94mif\u001b[0m file \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m file                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 324 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m file                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 325 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:511 in cached_files                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 508 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 509 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# We cannot recover from them\u001b[0m                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 510 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(e, RepositoryNotFoundError) \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(e, Gated \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 511 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mOSError\u001b[0m\u001b[1;4m(\u001b[0m                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 512 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4mpath_or_repo_id\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m is not a local folder and is not a valid \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 513 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mlisted on \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mhttps://huggingface.co/models\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m\\n\u001b[0m\u001b[1;4;33mIf this is a priv\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 514 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mhaving permission to this repo either by logging in with `hf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mOSError: \u001b[0myour-base-model-name is not a local folder and is not a valid model identifier \n",
      "listed on \u001b[32m'https://huggingface.co/models'\u001b[0m\n",
      "If this is a private repository, make sure to pass a token having permission to this \n",
      "repo either by logging in with `hf auth login` or by passing `\u001b[33mtoken\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95myour_token\u001b[0m\u001b[1m>\u001b[0m`\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_http.py\u001b[0m:402 in hf_raise_for_status                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m399 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m>         If request failed for a reason not listed above.\u001b[0m                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m400 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m402 \u001b[2m│   │   \u001b[0mresponse.raise_for_status()                                            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m403 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m HTTPError \u001b[94mas\u001b[0m e:                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   │   \u001b[0merror_code = response.headers.get(\u001b[33m\"\u001b[0m\u001b[33mX-Error-Code\u001b[0m\u001b[33m\"\u001b[0m)                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   │   \u001b[0merror_message = response.headers.get(\u001b[33m\"\u001b[0m\u001b[33mX-Error-Message\u001b[0m\u001b[33m\"\u001b[0m)                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/requests/\u001b[0m\u001b[1mmodels.p\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1my\u001b[0m:1026 in raise_for_status                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1023 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1024 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1025 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m http_error_msg:                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1026 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m HTTPError(http_error_msg, response=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m)\u001b[0m                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1027 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1028 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mclose\u001b[0m(\u001b[96mself\u001b[0m):                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1029 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Releases the connection back to the pool. Once this method has bee\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mHTTPError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error: Unauthorized for url: \n",
      "\u001b[4;94mhttps://huggingface.co/your-base-model-name/resolve/main/config.json\u001b[0m\n",
      "\n",
      "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:479 in cached_files                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 476 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 477 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(full_filenames) == \u001b[94m1\u001b[0m:                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 478 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# This is slightly better for only 1 file\u001b[0m                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 479 \u001b[2m│   │   │   \u001b[0mhf_hub_download(                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 480 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpath_or_repo_id,                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 481 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfilenames[\u001b[94m0\u001b[0m],                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 482 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:114 in _inner_fn                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, ha \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m117 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1007 in hf_hub_download                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1004 \u001b[0m\u001b[2m│   │   │   \u001b[0mlocal_files_only=local_files_only,                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1005 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1006 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1007 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4m_hf_hub_download_to_cache_dir(\u001b[0m                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1008 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;2;4m# Destination\u001b[0m                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1009 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mcache_dir=cache_dir,\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1010 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;2;4m# File info\u001b[0m                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1114 in _hf_hub_download_to_cache_dir                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1111 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m pointer_path                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1112 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1113 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Otherwise, raise appropriate error\u001b[0m                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1114 \u001b[2m│   │   \u001b[0m\u001b[1;4m_raise_on_head_call_error(head_call_error, force_download, local_file\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1115 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# From now on, etag, commit_hash, url and size are not None.\u001b[0m              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m etag \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33metag must have been retrieved from server\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1655 in _raise_on_head_call_error                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1652 \u001b[0m\u001b[2m│   \u001b[0m):                                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1653 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Repo not found or gated => let's raise the actual error\u001b[0m             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1654 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Unauthorized => likely a token issue => let's raise the actual erro\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1655 \u001b[2m│   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m head_call_error\u001b[0m                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1656 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1657 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Otherwise: most likely a connection issue or Hub downtime => let's \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1658 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m LocalEntryNotFoundError(                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1543 in _get_metadata_or_catch_error                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m local_files_only:                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1543 \u001b[2m│   │   │   │   \u001b[0mmetadata = get_hf_file_metadata(                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1544 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0murl=url, proxies=proxies, timeout=etag_timeout, headers=h \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1545 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1546 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m EntryNotFoundError \u001b[94mas\u001b[0m http_error:                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:114 in _inner_fn                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, ha \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m117 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:1460 in get_hf_file_metadata                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1457 \u001b[0m\u001b[2m│   \u001b[0mhf_headers[\u001b[33m\"\u001b[0m\u001b[33mAccept-Encoding\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[33m\"\u001b[0m\u001b[33midentity\u001b[0m\u001b[33m\"\u001b[0m  \u001b[2m# prevent any compression => \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1458 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1459 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Retrieve metadata\u001b[0m                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m1460 \u001b[2m│   \u001b[0mr = \u001b[1;4m_request_wrapper(\u001b[0m                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1461 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mmethod=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mHEAD\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m,\u001b[0m                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1462 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4murl=url,\u001b[0m                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m1463 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mheaders=hf_headers,\u001b[0m                                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:283 in _request_wrapper                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 280 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 281 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Recursively follow relative redirects\u001b[0m                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 282 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m follow_relative_redirects:                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 283 \u001b[2m│   │   \u001b[0mresponse = \u001b[1;4m_request_wrapper(\u001b[0m                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 284 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mmethod=method,\u001b[0m                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 285 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4murl=url,\u001b[0m                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 286 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4mfollow_relative_redirects=\u001b[0m\u001b[1;4;94mFalse\u001b[0m\u001b[1;4m,\u001b[0m                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/\u001b[0m\u001b[1mf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1mile_download.py\u001b[0m:307 in _request_wrapper                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 304 \u001b[0m\u001b[2m│   \u001b[0m                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 305 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Perform request and return if status_code is not in the retry list.\u001b[0m     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 306 \u001b[0m\u001b[2m│   \u001b[0mresponse = http_backoff(method=method, url=url, **params)                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 307 \u001b[2m│   \u001b[0m\u001b[1;4mhf_raise_for_status(response)\u001b[0m                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m response                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 309 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 310 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_http.py\u001b[0m:452 in hf_raise_for_status                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m449 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m make sure you are authenticated. For more details, see\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m450 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[0m\u001b[33m\"\u001b[0m  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m451 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m452 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m _format(RepositoryNotFoundError, message, response) \u001b[0m\u001b[1;4;94mfrom\u001b[0m\u001b[1;4;90m \u001b[0m\u001b[1;4;96me\u001b[0m   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m453 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m454 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m response.status_code == \u001b[94m400\u001b[0m:                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m455 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage = (                                                        \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mRepositoryNotFoundError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error. \u001b[1m(\u001b[0mRequest ID: \n",
      "\u001b[33mRoot\u001b[0m=\u001b[1;36m1\u001b[0m-\u001b[1;36m695255e8\u001b[0m-722fdbb02c3e826b4f1252c3;\u001b[93m48234ee7-3c57-4452-a92c-3465c7c40d8d\u001b[0m\u001b[1m)\u001b[0m\n",
      "\n",
      "Repository Not Found for url: \n",
      "\u001b[4;94mhttps://huggingface.co/your-base-model-name/resolve/main/config.json.\u001b[0m\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated. \n",
      "For more details, see \u001b[4;94mhttps://huggingface.co/docs/huggingface_hub/authentication\u001b[0m\n",
      "Invalid username or password.\n",
      "\n",
      "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mexec_code.py\u001b[0m:129 in exec_func_with_error_handling                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mscript_runner.py\u001b[0m:671 in code_to_exec                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:108 in <module>                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0mmodel.eval()                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer, model                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m107 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m108 tokenizer, model = \u001b[1;4mload_model()\u001b[0m                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m109 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m# -------------------------------\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m# Prompt Input\u001b[0m                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:228 in __call__                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:270 in _get_or_create_cached_value                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:329 in _handle_cache_miss                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:99 in load_model                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 96 \u001b[0m\u001b[1;95m@st\u001b[0m.cache_resource                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 97 \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mload_model\u001b[0m():                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   \u001b[0mtokenizer = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[0m\u001b[33mmistralai/Mistral-7B-v0.1\u001b[0m\u001b[33m\"\u001b[0m)     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 99 \u001b[2m│   \u001b[0mmodel = \u001b[1;4mAutoModelForCausalLM.from_pretrained(\u001b[0m                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33myour-base-model-name\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m,\u001b[0m                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mdevice_map=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mauto\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m,\u001b[0m                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;4mtorch_dtype=torch.float16\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/mode\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mls/auto/\u001b[0m\u001b[1mauto_factory.py\u001b[0m:508 in from_pretrained                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m505 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m commit_hash \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m506 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(config, PretrainedConfig):                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m507 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# We make a call to the config file first (which may be absent\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m508 \u001b[2m│   │   │   │   \u001b[0mresolved_config_file = \u001b[1;4mcached_file(\u001b[0m                            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m509 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[1;4mpretrained_model_name_or_path,\u001b[0m                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m510 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[1;4mCONFIG_NAME,\u001b[0m                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m511 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[1;4m_raise_exceptions_for_gated_repo=\u001b[0m\u001b[1;4;94mFalse\u001b[0m\u001b[1;4m,\u001b[0m                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:322 in cached_file                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 319 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mmodel_weights_file = cached_file(\"google-bert/bert-base-uncased\", \"pytorc\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 320 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m```\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 321 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 322 \u001b[2m│   \u001b[0mfile = \u001b[1;4mcached_files(path_or_repo_id=path_or_repo_id, filenames=[filename]\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 323 \u001b[0m\u001b[2m│   \u001b[0mfile = file[\u001b[94m0\u001b[0m] \u001b[94mif\u001b[0m file \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m file                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 324 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m file                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 325 \u001b[0m                                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/util\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2ms/\u001b[0m\u001b[1mhub.py\u001b[0m:511 in cached_files                                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 508 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 509 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# We cannot recover from them\u001b[0m                                         \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 510 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(e, RepositoryNotFoundError) \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(e, Gated \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 511 \u001b[2m│   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mOSError\u001b[0m\u001b[1;4m(\u001b[0m                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 512 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4mpath_or_repo_id\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m is not a local folder and is not a valid \u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 513 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mlisted on \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mhttps://huggingface.co/models\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m\\n\u001b[0m\u001b[1;4;33mIf this is a priv\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 514 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mhaving permission to this repo either by logging in with `hf\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mOSError: \u001b[0myour-base-model-name is not a local folder and is not a valid model identifier \n",
      "listed on \u001b[32m'https://huggingface.co/models'\u001b[0m\n",
      "If this is a private repository, make sure to pass a token having permission to this \n",
      "repo either by logging in with `hf auth login` or by passing `\u001b[33mtoken\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95myour_token\u001b[0m\u001b[1m>\u001b[0m`\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/peft/\u001b[0m\u001b[1mconfig.py\u001b[0m:31 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m 7 in _get_peft_type                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m314 \u001b[0m\u001b[2m│   │   │   \u001b[0mconfig_file = os.path.join(path, CONFIG_NAME)                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m315 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m316 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m317 \u001b[2m│   │   │   │   \u001b[0mconfig_file = hf_hub_download(                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m318 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmodel_id,                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m319 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mCONFIG_NAME,                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m320 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m**hf_hub_download_kwargs,                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:106 in _inner_fn                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs.items(),  \u001b[2m# Kwargs values\u001b[0m                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m arg_name \u001b[95min\u001b[0m [\u001b[33m\"\u001b[0m\u001b[33mrepo_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mfrom_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mto_id\u001b[0m\u001b[33m\"\u001b[0m]:                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m106 \u001b[2m│   │   │   │   \u001b[0m\u001b[1;4mvalidate_repo_id(arg_value)\u001b[0m                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m arg_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhas_token = \u001b[94mTrue\u001b[0m                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/huggingface_hub/u\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2mtils/\u001b[0m\u001b[1m_validators.py\u001b[0m:160 in validate_repo_id                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   \u001b[0m                                                                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m REPO_ID_REGEX.match(repo_id):                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m160 \u001b[2m│   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m HFValidationError(\u001b[0m                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mRepo id must use alphanumeric chars, \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m-\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m, \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m_\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m or \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m.\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m.\u001b[0m\u001b[1;4;33m\"\u001b[0m            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m The name cannot start or end with \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m-\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m or \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m.\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m and the maximum len\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33m \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4mrepo_id\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m.\u001b[0m\u001b[1;4;33m\"\u001b[0m                                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mHFValidationError: \u001b[0mRepo id must use alphanumeric chars, \u001b[32m'-'\u001b[0m, \u001b[32m'_'\u001b[0m or \u001b[32m'.'\u001b[0m. The name cannot\n",
      "start or end with \u001b[32m'-'\u001b[0m or \u001b[32m'.'\u001b[0m and the maximum length is \u001b[1;36m96\u001b[0m: \u001b[32m'lora_adapters/'\u001b[0m.\n",
      "\n",
      "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mexec_code.py\u001b[0m:129 in exec_func_with_error_handling                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/scriptrunner/\u001b[0m\u001b[1mscript_runner.py\u001b[0m:671 in code_to_exec                                   \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:108 in <module>                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0mmodel.eval()                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer, model                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m107 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m108 tokenizer, model = \u001b[1;4mload_model()\u001b[0m                                                \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m109 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m# -------------------------------\u001b[0m                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m# Prompt Input\u001b[0m                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:228 in __call__                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:270 in _get_or_create_cached_value                           \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/caching/\u001b[0m\u001b[1mcache_utils.py\u001b[0m:329 in _handle_cache_miss                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/teamspace/studios/this_studio/\u001b[0m\u001b[1mapp.py\u001b[0m:104 in load_model                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   \u001b[0mdevice_map=\u001b[33m\"\u001b[0m\u001b[33mauto\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   │   \u001b[0mtorch_dtype=torch.float16                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   \u001b[0m)                                                                          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m104 \u001b[2m│   \u001b[0mmodel = \u001b[1;4mPeftModel.from_pretrained(model, \u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mlora_adapters/\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m)\u001b[0m                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   \u001b[0mmodel.eval()                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m tokenizer, model                                                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m107 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/peft/\u001b[0m\u001b[1mpeft_model.p\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[1my\u001b[0m:459 in from_pretrained                                                             \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 456 \u001b[0m\u001b[2m│   │   │   \u001b[0m}                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 457 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m use_auth_token := kwargs.get(\u001b[33m\"\u001b[0m\u001b[33muse_auth_token\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m):          \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 458 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhf_kwargs[\u001b[33m\"\u001b[0m\u001b[33muse_auth_token\u001b[0m\u001b[33m\"\u001b[0m] = use_auth_token                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 459 \u001b[2m│   │   │   \u001b[0mconfig = PEFT_TYPE_TO_CONFIG_MAPPING[\u001b[1;4mPeftConfig._get_peft_type(mo\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 460 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_id, **kwargs                                            \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 461 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m 462 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(config, PeftConfig):                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[2m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/peft/\u001b[0m\u001b[1mconfig.py\u001b[0m:32 \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m 3 in _get_peft_type                                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m320 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m**hf_hub_download_kwargs,                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m321 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                              \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m322 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m323 \u001b[2m│   │   │   │   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mValueError\u001b[0m\u001b[1;4m(\u001b[0m\u001b[1;4;33mf\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33mCan\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mt find \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4mCONFIG_NAME\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m at \u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m{\u001b[0m\u001b[1;4mmodel_id\u001b[0m\u001b[1;4;33m}\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33m\"\u001b[0m \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                       \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   │   \u001b[0mloaded_attributes = \u001b[96mcls\u001b[0m.from_json_file(config_file)                    \u001b[31m \u001b[0m\n",
      "\u001b[31m \u001b[0m   \u001b[2m326 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loaded_attributes[\u001b[33m\"\u001b[0m\u001b[33mpeft_type\u001b[0m\u001b[33m\"\u001b[0m]                                  \u001b[31m \u001b[0m\n",
      "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;91mValueError: \u001b[0mCan't find \u001b[32m'adapter_config.json'\u001b[0m at \u001b[32m'lora_adapters/'\u001b[0m\n",
      "2025-12-29 10:26:56.755 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 97\n",
      "    import os\n",
      "    ^^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "2025-12-29 10:26:56.757 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 97\n",
      "    import os\n",
      "    ^^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "2025-12-29 10:26:56.759 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-29 10:27:00.321 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 97\n",
      "    import os\n",
      "    ^^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "2025-12-29 10:27:00.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-29 10:27:00.323 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 97\n",
      "    import os\n",
      "    ^^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "2025-12-29 10:27:00.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-29 10:27:17.563 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 97\n",
      "    import os\n",
      "    ^^^^^^\n",
      "SyntaxError: invalid syntax\n",
      "2025-12-29 10:27:17.564 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "2025-12-29 10:29:50.782 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 37\n",
      "    padding: 20px;\n",
      "              ^\n",
      "SyntaxError: invalid decimal literal\n",
      "2025-12-29 10:29:50.783 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-29 10:29:55.737 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 46\n",
      "    font-size: 2.2rem;\n",
      "                 ^\n",
      "SyntaxError: invalid decimal literal\n",
      "2025-12-29 10:29:55.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-29 10:30:26.649 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 44\n",
      "    font-size: 2.2rem;\n",
      "                 ^\n",
      "SyntaxError: invalid decimal literal\n",
      "2025-12-29 10:30:26.650 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-29 10:30:26.847 Script compilation error\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 573, in _run_script\n",
      "    code = self._script_cache.get_bytecode(script_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_cache.py\", line 72, in get_bytecode\n",
      "    filebody = magic.add_magic(filebody, script_path)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/magic.py\", line 45, in add_magic\n",
      "    tree = ast.parse(code, script_path, \"exec\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 44\n",
      "    font-size: 2.2rem;\n",
      "                 ^\n",
      "SyntaxError: invalid decimal literal\n",
      "2025-12-29 10:30:26.848 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "2025-12-29 10:36:21.232 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 159, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:36:28.062 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 159, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:36:47.289 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 159, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:36:47.497 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 159, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:37:47.807 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 159, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "2025-12-29 10:38:57.399 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 154, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:39:13.839 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 154, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:39:14.048 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 154, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:39:19.407 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 154, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:41:10.570 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 169, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:41:15.115 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 169, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:41:57.005 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 169, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:42:04.548 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 169, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:42:19.821 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 169, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:43:22.174 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:43:49.849 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:43:50.046 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:45:51.402 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:45:57.719 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:46:08.899 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:46:09.110 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:47:36.396 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:47:36.608 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:47:38.668 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 181, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "2025-12-29 10:49:02.583 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 207, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n",
      "2025-12-29 10:49:21.320 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
      "Stack (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 378, in _run_script_thread\n",
      "    self._run_script(request.rerun_data)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 687, in _run_script\n",
      "    ) = exec_func_with_error_handling(code_to_exec, ctx)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/exec_code.py\", line 129, in exec_func_with_error_handling\n",
      "    result = func()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 671, in code_to_exec\n",
      "    exec(code, module.__dict__)  # noqa: S102\n",
      "  File \"/teamspace/studios/this_studio/app.py\", line 207, in <module>\n",
      "    prompt = st.text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 531, in wrapped_func\n",
      "    result = non_optional_func(*args, **kwargs)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 600, in text_area\n",
      "    return self._text_area(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/widgets/text_widgets.py\", line 643, in _text_area\n",
      "    maybe_raise_label_warnings(label, label_visibility)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/streamlit/elements/lib/policies.py\", line 184, in maybe_raise_label_warnings\n",
      "    _LOGGER.warning(\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "BASE_MODEL = \"mistralai/Mistral-7B-v0.1\"\n",
    "CHECKPOINT = \"./cs_lora_output_model/checkpoint-1500\"\n",
    "EXPORT_DIR = \"./lora_adapters_final\"\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load LoRA from checkpoint\n",
    "model = PeftModel.from_pretrained(base_model, CHECKPOINT)\n",
    "\n",
    "# Save adapters in inference-ready format\n",
    "model.save_pretrained(EXPORT_DIR)\n",
    "\n",
    "print(\"✅ LoRA adapters exported to:\", EXPORT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ./lora_adapters_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "004163d810854bcb9525594376c696ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "006511decc0a46528da7b0ee6504f9a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e33ef60907b4e3992b18f8fffe58061",
      "max": 996,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fd8f20f41154a328fa854c230b9e30d",
      "value": 996
     }
    },
    "02a9a393f2554088bdbbf1dce2662f1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02c5a0ccbb554045ad4d06a8c2fe527e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03774901f5654c6d90361bbd9f959d22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2b2723b0e9b402981efeeb5c03dbe71",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_713756b449e1455d8a29ac21125c6644",
      "value": 2
     }
    },
    "0418b3cc6dfd445cac9b314497c24441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb45f6fee56b47ad92d8e0d34b20dadd",
      "max": 116,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95489b313d1e4390ac4db0ea57c134e7",
      "value": 116
     }
    },
    "04a23499a28e4563ad703d17223fd883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0543b1d8f4064981b101cdca98114967": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05fb6ddb6bfb4293a8acdb4a433ff452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_143b764662604e8fb3a59a82325ad3fe",
      "max": 9942981696,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ced686043734cdea3b76bde6d07abce",
      "value": 9942981696
     }
    },
    "0701cc4ff04b4383b3a54d64d7197430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "09d4091708b5489f8d9beccf7ad426e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0cb531b627f64295bf8bbda12af45d78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cf8122cdacd44159c10200d95739ac7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e7156291fab461db23b43df05d1d9af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_196eca3cb3df4c54847f457e15bed1be",
       "IPY_MODEL_88540ea0bb4b49d09cec3606a9f41bc4",
       "IPY_MODEL_e3f868262f65454c9253b2cb1d104a50"
      ],
      "layout": "IPY_MODEL_ef8907524dbe4e90af3449d32b75ae63"
     }
    },
    "10d7d5ebdbab418184b269d794f69899": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6146b156dc404eb79bf04a31552a3ee8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09d4091708b5489f8d9beccf7ad426e7",
      "value": 1
     }
    },
    "111f8108dc33411a94424555c8f61764": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bee727d082874e96ade6c87ad554c0dd",
      "placeholder": "​",
      "style": "IPY_MODEL_e2ca8236080e4ee9b7377f717663d598",
      "value": " 996/996 [00:00&lt;00:00, 103kB/s]"
     }
    },
    "12aeeb1349d04cea98ec7728ae7ba6d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_659012a1b859460681fae79f384a20f9",
      "placeholder": "​",
      "style": "IPY_MODEL_b3a85c92897948c0af219dab8fe219e3",
      "value": " 10.0k/? [00:00&lt;00:00, 488kB/s]"
     }
    },
    "141cf542cc8e4053b7e56a0d716edc22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "143b764662604e8fb3a59a82325ad3fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14418b67a8484f15bd7443b0ba46bf49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14da0ed71f0f472785b80fdfcd742a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1787d1eaa2a3494bac5a55911eab1ac9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "196eca3cb3df4c54847f457e15bed1be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0543b1d8f4064981b101cdca98114967",
      "placeholder": "​",
      "style": "IPY_MODEL_980f2f13b1f242e6b8f7bcaedba9d19b",
      "value": "Map: 100%"
     }
    },
    "1b98a414a7614af48d1a9bba31831c81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3b62cec75044a3f8818088418889e1b",
      "placeholder": "​",
      "style": "IPY_MODEL_5d853302c75e4954b0cb73bdd7d47a17",
      "value": " 414/414 [00:00&lt;00:00, 37.7kB/s]"
     }
    },
    "1c1c90b4558d4b07aca97113a321489e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f960e5f011e0483a99394c9a6100c64f",
      "placeholder": "​",
      "style": "IPY_MODEL_f5b3ac9d591148758489b6def986ac59",
      "value": " 47789/47789 [00:08&lt;00:00, 6504.67 examples/s]"
     }
    },
    "1c8dc4a9c3cf4036a35fed424aed2b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb7167302776440fa94dfe4f2466cabc",
       "IPY_MODEL_0418b3cc6dfd445cac9b314497c24441",
       "IPY_MODEL_9e62e9f7e1d14c8bbaa3c71ef6ad52fe"
      ],
      "layout": "IPY_MODEL_caa6f7cd722e4d35a552c1b038126d15"
     }
    },
    "1cbf672d86ee41f4a61b6c7819807300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3528f55f4cc4423a152b68acb05bc23",
       "IPY_MODEL_fcba1ff6aaeb465c9cda02bc7dde0692",
       "IPY_MODEL_e98d34abe8a147c9a586b48ef2dd8536"
      ],
      "layout": "IPY_MODEL_a2c7b4151ba342fb9faf2bbb2c25d216"
     }
    },
    "1e33ef60907b4e3992b18f8fffe58061": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f113b48b236498f826ff4028b38f64e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fccb39eac1f4b67a98d6aa2afebb00b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ff1ea50838b4b169014d8358a70cff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f38334b8b96478b8f21429cf231c067",
      "placeholder": "​",
      "style": "IPY_MODEL_93eaa7cca2434bd292a214b457eb907e",
      "value": " 1.80M/? [00:00&lt;00:00, 47.7MB/s]"
     }
    },
    "1ffd9c19f7bb4162b337e1ebf7fc1bb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21358af5e2304de99eb451b887194178": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7beb173011d14d53a4af746d6c4f17c7",
       "IPY_MODEL_e752cec41b4f4721bf7de91aead1e9c8",
       "IPY_MODEL_a2b7258c36a54db29658534ccf6f9196"
      ],
      "layout": "IPY_MODEL_b11178c9eb6345f7acccb4364945c170"
     }
    },
    "23857b0b34044e94a057fd5d79a403b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2451daf7fb8a45d29f26e920dfe94096": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90b0e72a7851482aa048ff77e26d20b1",
      "placeholder": "​",
      "style": "IPY_MODEL_e3f5578fe80c459e8902e52046c298a4",
      "value": " 2/2 [04:16&lt;00:00, 105.59s/it]"
     }
    },
    "261bdc88ef924173b2228b4ff0f256ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a02b5fbbad6c4b0883d4fe652a6bd5ff",
       "IPY_MODEL_6892ac3071354196b2855a42a250e060",
       "IPY_MODEL_8cd610e6a63b47cca572f6f996d13aa7"
      ],
      "layout": "IPY_MODEL_ecdd75856b70440d93555b16b9f0ecde"
     }
    },
    "2904d5798e82499ab2c78df46979aba3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29469aac113848488ab60bbec67454dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a6af08be437470db24d89f1bd29b7d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a8b349d5e644697b27d504e6325f31c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b7908894f9e4011aaf12e5d59b20eeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb3b57f67fa64a7a9f8748f53abd58e3",
      "placeholder": "​",
      "style": "IPY_MODEL_4c91aa5ec08c4043a25276b18e08aadb",
      "value": " 47789/47789 [00:05&lt;00:00, 54417.27 examples/s]"
     }
    },
    "2f249d07f34a42909a79a31ed147bed8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f38334b8b96478b8f21429cf231c067": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3105edfb44414d80ae3058d248691a4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "38940f0a5bd84c06b9c34dd85f820ff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4b7a8a515174420a343fc1669f4c274",
      "placeholder": "​",
      "style": "IPY_MODEL_9197016531574c908da6ae2f020019e4",
      "value": " 2/2 [01:19&lt;00:00, 36.79s/it]"
     }
    },
    "3bcce06b8b61405da1e0462eac962201": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c739c39465a4b8286950aca098f95a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3ced686043734cdea3b76bde6d07abce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e85f77bb0db44e59f8bf2ceabcb89d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "406fe2406e114c138bd1cdab42e2d43c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40819514217e43feb14aa56ce860a419": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4165959fc733406fbeba6ab44be23f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "432c9ac09150499db69f3563ad822174": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43a5333d499f4541908e0773a668d16e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44078e74339e487a9d8553a27d78c942": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_953d40aa0f1c498d89b4140bf2ee8e87",
      "max": 47789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_63a85ed0dc674ce5b620e50acdd165a9",
      "value": 47789
     }
    },
    "442f4c89b16c44eb9b9561ed49758215": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4552c0690447446580e8d1bf9f8238f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4729a4602c6a426baaf30eaadd173b31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cabfb911fac489086077605c24d5675",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e85f77bb0db44e59f8bf2ceabcb89d0",
      "value": 2
     }
    },
    "4878901af9034b90a4aeca3664418e7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90df82aab4d54bcc84440860381614ac",
      "max": 47789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3105edfb44414d80ae3058d248691a4d",
      "value": 47789
     }
    },
    "49499c6e2f46442d936807dbbb7a7516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af073d0974ff47fa8c4f83e9c826ddf8",
       "IPY_MODEL_fab2ada1292a4452af59462d2b59f000",
       "IPY_MODEL_1b98a414a7614af48d1a9bba31831c81"
      ],
      "layout": "IPY_MODEL_97afa5f31efc476982034ac7015ee2a6"
     }
    },
    "4ade69e8fccc40e39d63c2e095d0d206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9fcc0f4561343518f41ecfd0b35d24c",
      "max": 47789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d01bce1463c4514a935b99657906b69",
      "value": 47789
     }
    },
    "4b1a1e7cee9e4649a1bae4619028c4d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c91aa5ec08c4043a25276b18e08aadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4da7bf091f0142cf9719b2b529f47a6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4dea8d4120cc44f887212dd985eda300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a07b0b4f63394fe8a30c2ccf09e6a038",
      "placeholder": "​",
      "style": "IPY_MODEL_ff6deeea5a1a4117b749ee5356c1cd81",
      "value": "tokenizer.json: "
     }
    },
    "4eec48e6009a4b00a46e193e672dad52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5018c4b1fddd4d7598887c5ed953b23a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51628f36f98c4e0eb9aa79c053f007e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5374fb4313f440adbc2b9afe3b5407c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "548ee71a246c45a79671a05855ce33cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "552eca8cdcad4c798467a20a8ad75dee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c5d2ae093c4b6890c23d9ff742c4a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad19fe93194b416a82c75339cd7d6a1d",
      "placeholder": "​",
      "style": "IPY_MODEL_442f4c89b16c44eb9b9561ed49758215",
      "value": " 47789/47789 [00:09&lt;00:00, 6061.49 examples/s]"
     }
    },
    "56cc182bab934d25bbf9c58fd7c48918": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aac57d99af8e416a8f334d1552c6828a",
      "placeholder": "​",
      "style": "IPY_MODEL_c6b6fe27c057443aaad751c60f741a51",
      "value": "Generating train split: 100%"
     }
    },
    "5829c577198240f9840cd19781f95ac0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9968dc55f4b54914879a2a2530ba145e",
       "IPY_MODEL_5d1e321641a1427997ff3c73d15f97cc",
       "IPY_MODEL_1c1c90b4558d4b07aca97113a321489e"
      ],
      "layout": "IPY_MODEL_0cf8122cdacd44159c10200d95739ac7"
     }
    },
    "58c98d5c77124706999903e8fc7cfb76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a7e20494e6e435b886d33fd03fdbd3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5be4cb6fdf5948b48ca74322346cf10d",
      "max": 571,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a2f61d4767c4a908ee51597fe9c005d",
      "value": 571
     }
    },
    "5be4cb6fdf5948b48ca74322346cf10d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c507246ba1241f5b56ae6cf951ebe9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd10fbeb89994271838ae05e88133ec6",
       "IPY_MODEL_44078e74339e487a9d8553a27d78c942",
       "IPY_MODEL_8ec1fc4ab6954d8da68b1e2e73abb149"
      ],
      "layout": "IPY_MODEL_1fccb39eac1f4b67a98d6aa2afebb00b"
     }
    },
    "5c86bb71d48b4b1a84d33ff1ab77b12c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ce874e636b5431f87e3d87307c0f78a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5d1add9086ed469ba6050c78b2494575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d1e321641a1427997ff3c73d15f97cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ffd9c19f7bb4162b337e1ebf7fc1bb7",
      "max": 47789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e4486343356428f93d801446e1c0075",
      "value": 47789
     }
    },
    "5d853302c75e4954b0cb73bdd7d47a17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f48c693a66c489ab58ae973cb154dfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebf5ac08ec7b419ebcc607f7ce6ee267",
       "IPY_MODEL_df0d0acfddc3464f9999162bb755135e",
       "IPY_MODEL_67640e581ccc4680aac93c4347f29442"
      ],
      "layout": "IPY_MODEL_432c9ac09150499db69f3563ad822174"
     }
    },
    "5f5c2641cc2e4f769f1ed1dcf3512a76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ff9a764a1ee49269e2a10fe5d27f496": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6146b156dc404eb79bf04a31552a3ee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "635bebfa0b5b4f9eb2dffcc629997509": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63a85ed0dc674ce5b620e50acdd165a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "659012a1b859460681fae79f384a20f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6715faa3e5264951b1f14d71c974dd83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67640e581ccc4680aac93c4347f29442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f25624c9a19a42eabe048d8817de859b",
      "placeholder": "​",
      "style": "IPY_MODEL_6715faa3e5264951b1f14d71c974dd83",
      "value": " 493k/493k [00:00&lt;00:00, 2.33MB/s]"
     }
    },
    "67738e6ae6c4491e96e6240fbde81a88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6892ac3071354196b2855a42a250e060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4eec48e6009a4b00a46e193e672dad52",
      "max": 4540516344,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0701cc4ff04b4383b3a54d64d7197430",
      "value": 4540516344
     }
    },
    "6c5daf8b18b64a5c927ad836159ee610": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e577a80eed342b99bbed8d357819695": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e6ba79d3df845678d2f9f4007f8c1eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51628f36f98c4e0eb9aa79c053f007e6",
      "placeholder": "​",
      "style": "IPY_MODEL_2a8b349d5e644697b27d504e6325f31c",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "6f1cc3a8ae3c4a3fa9bc03044472681e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "713756b449e1455d8a29ac21125c6644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72a8532ee2144122b5d1691868553f0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73040ef05563475eba6a7fc6b4dec500": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8428771923ae40a281892cd57ce3610d",
      "placeholder": "​",
      "style": "IPY_MODEL_5018c4b1fddd4d7598887c5ed953b23a",
      "value": "README.md: "
     }
    },
    "734af2f1b363475984231c77684d26fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5ca926cf3014bb3b02213d19b5174ae",
      "placeholder": "​",
      "style": "IPY_MODEL_b63f50456dcb463684c64fa82368fcaa",
      "value": "model.safetensors.index.json: "
     }
    },
    "7391b82b0e0a46c5a7dd88b8dbef17b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f26cf7b742c478098c9a0771ecd4b09",
      "placeholder": "​",
      "style": "IPY_MODEL_d142c4238fa948de850a0cb2edbd2505",
      "value": "Fetching 2 files: 100%"
     }
    },
    "753ebf3faae646f8aaf89d17a1037c60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775815fabf6f4c308ae82bcdd232e236": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "775d5e3b8ddd4efba45a087792fd20ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "788a1ec3cb1f435d9df347bc9a17d3f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7391b82b0e0a46c5a7dd88b8dbef17b8",
       "IPY_MODEL_4729a4602c6a426baaf30eaadd173b31",
       "IPY_MODEL_2451daf7fb8a45d29f26e920dfe94096"
      ],
      "layout": "IPY_MODEL_b608a5c66cb24895944921b352c166d0"
     }
    },
    "7beb173011d14d53a4af746d6c4f17c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e25dcee5dc454f2686a5dda5953bca2c",
      "placeholder": "​",
      "style": "IPY_MODEL_406fe2406e114c138bd1cdab42e2d43c",
      "value": "Alpie-core_core_indian_dataset.json: 100%"
     }
    },
    "7c2f0f86d3fd4a409b16dbc1f2c8d2ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d01bce1463c4514a935b99657906b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f1b07885bcd4ee1a600c25669325380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "81566870baa148bbb7869d3f60be5a10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c739c39465a4b8286950aca098f95a4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f1b07885bcd4ee1a600c25669325380",
      "value": 1
     }
    },
    "820835573270442f8eca304fac49d44a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_552eca8cdcad4c798467a20a8ad75dee",
      "placeholder": "​",
      "style": "IPY_MODEL_5c86bb71d48b4b1a84d33ff1ab77b12c",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "8428771923ae40a281892cd57ce3610d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "853c4084ccaf4945863f3a26a89a7ccd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "875de1949ab34611a345d19eb1e47d20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88540ea0bb4b49d09cec3606a9f41bc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5374fb4313f440adbc2b9afe3b5407c2",
      "max": 47789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c01095a1c46f4446860d55841c2baddd",
      "value": 47789
     }
    },
    "8a2f61d4767c4a908ee51597fe9c005d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a580e0b60f24a13b241eeab37f437f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cabfb911fac489086077605c24d5675": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cd610e6a63b47cca572f6f996d13aa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5cbea18f5da44779a54e833e2c174c8",
      "placeholder": "​",
      "style": "IPY_MODEL_4da7bf091f0142cf9719b2b529f47a6a",
      "value": " 4.54G/4.54G [04:16&lt;00:00, 24.1MB/s]"
     }
    },
    "8e7278d17bf740b08dec718852047e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ec1fc4ab6954d8da68b1e2e73abb149": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1787d1eaa2a3494bac5a55911eab1ac9",
      "placeholder": "​",
      "style": "IPY_MODEL_775d5e3b8ddd4efba45a087792fd20ce",
      "value": " 47789/47789 [00:06&lt;00:00, 6941.66 examples/s]"
     }
    },
    "90b0e72a7851482aa048ff77e26d20b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90df82aab4d54bcc84440860381614ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9197016531574c908da6ae2f020019e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92b34371890e481b903b37a2136914e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93b6776e827246a8a11afa5fb7dc022c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93eaa7cca2434bd292a214b457eb907e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "953d40aa0f1c498d89b4140bf2ee8e87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95489b313d1e4390ac4db0ea57c134e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9706ef52c7344df0abc27510c69b8bae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97afa5f31efc476982034ac7015ee2a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "980f2f13b1f242e6b8f7bcaedba9d19b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98a7565ef51b44cb838525e3b51497fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9968dc55f4b54914879a2a2530ba145e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92b34371890e481b903b37a2136914e3",
      "placeholder": "​",
      "style": "IPY_MODEL_7c2f0f86d3fd4a409b16dbc1f2c8d2ba",
      "value": "Map: 100%"
     }
    },
    "9e4486343356428f93d801446e1c0075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e62e9f7e1d14c8bbaa3c71ef6ad52fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29469aac113848488ab60bbec67454dd",
      "placeholder": "​",
      "style": "IPY_MODEL_c189b34d3d8c49d284fb6a2ac066ae80",
      "value": " 116/116 [00:00&lt;00:00, 10.5kB/s]"
     }
    },
    "9f26cf7b742c478098c9a0771ecd4b09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fd8f20f41154a328fa854c230b9e30d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a02b5fbbad6c4b0883d4fe652a6bd5ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cb531b627f64295bf8bbda12af45d78",
      "placeholder": "​",
      "style": "IPY_MODEL_3bcce06b8b61405da1e0462eac962201",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    },
    "a07b0b4f63394fe8a30c2ccf09e6a038": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2b7258c36a54db29658534ccf6f9196": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a580e0b60f24a13b241eeab37f437f2",
      "placeholder": "​",
      "style": "IPY_MODEL_548ee71a246c45a79671a05855ce33cd",
      "value": " 258M/258M [00:05&lt;00:00, 44.7MB/s]"
     }
    },
    "a2c7b4151ba342fb9faf2bbb2c25d216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3476e8392764a83a3241d553c7a49f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a476180b84834b299abc15d9d10c266a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4552c0690447446580e8d1bf9f8238f6",
      "placeholder": "​",
      "style": "IPY_MODEL_1f113b48b236498f826ff4028b38f64e",
      "value": " 47789/47789 [00:08&lt;00:00, 5632.71 examples/s]"
     }
    },
    "a4f8be4cf6ad4da89fb1259a92802cc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a60308756f024813a67239e7978cafec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2d282888aa14995bf694dabf38b5fd8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e577a80eed342b99bbed8d357819695",
      "value": 1
     }
    },
    "a762068bc11c422196c8fd49c170ccf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d478e7e548144f75b1f399b5719c3ffc",
      "placeholder": "​",
      "style": "IPY_MODEL_8e7278d17bf740b08dec718852047e5a",
      "value": " 9.94G/9.94G [04:15&lt;00:00, 75.4MB/s]"
     }
    },
    "a8c2a39dca924565aea77d407e9937be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_820835573270442f8eca304fac49d44a",
       "IPY_MODEL_05fb6ddb6bfb4293a8acdb4a433ff452",
       "IPY_MODEL_a762068bc11c422196c8fd49c170ccf2"
      ],
      "layout": "IPY_MODEL_853c4084ccaf4945863f3a26a89a7ccd"
     }
    },
    "a8d45a7ebd8a4c41baffe0e11fd89cd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e6ba79d3df845678d2f9f4007f8c1eb",
       "IPY_MODEL_03774901f5654c6d90361bbd9f959d22",
       "IPY_MODEL_38940f0a5bd84c06b9c34dd85f820ff4"
      ],
      "layout": "IPY_MODEL_4165959fc733406fbeba6ab44be23f9d"
     }
    },
    "a9093f1ed697493e8a1793c379561104": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aac57d99af8e416a8f334d1552c6828a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abea1734b11b48dbac39e573529a6899": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad19fe93194b416a82c75339cd7d6a1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af073d0974ff47fa8c4f83e9c826ddf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_004163d810854bcb9525594376c696ab",
      "placeholder": "​",
      "style": "IPY_MODEL_da43154eeef74b12bf991f7fb0d92bdf",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "b11178c9eb6345f7acccb4364945c170": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1c0f721617e412891fc5da53f80d054": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_73040ef05563475eba6a7fc6b4dec500",
       "IPY_MODEL_a60308756f024813a67239e7978cafec",
       "IPY_MODEL_12aeeb1349d04cea98ec7728ae7ba6d2"
      ],
      "layout": "IPY_MODEL_e5048fd751f14077bb1eabbf614f49d7"
     }
    },
    "b3a85c92897948c0af219dab8fe219e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4f3ac777d334459aa15db6f513ab516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4fa38cc4a964827831bc03f640d51c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02a9a393f2554088bdbbf1dce2662f1d",
      "placeholder": "​",
      "style": "IPY_MODEL_2f249d07f34a42909a79a31ed147bed8",
      "value": "Map: 100%"
     }
    },
    "b5f8423cf5e943f6a038834bf432e9f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b608a5c66cb24895944921b352c166d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63f50456dcb463684c64fa82368fcaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be8c1b2248474fb3b137bb2f3ed3f136": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bee727d082874e96ade6c87ad554c0dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c01095a1c46f4446860d55841c2baddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c189b34d3d8c49d284fb6a2ac066ae80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2d282888aa14995bf694dabf38b5fd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "c30000f0e53d41029f599a5b064c70aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_734af2f1b363475984231c77684d26fd",
       "IPY_MODEL_10d7d5ebdbab418184b269d794f69899",
       "IPY_MODEL_c3be5e44f8a54108b93d9430ac59ec0d"
      ],
      "layout": "IPY_MODEL_4b1a1e7cee9e4649a1bae4619028c4d1"
     }
    },
    "c3be5e44f8a54108b93d9430ac59ec0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40819514217e43feb14aa56ce860a419",
      "placeholder": "​",
      "style": "IPY_MODEL_5ff9a764a1ee49269e2a10fe5d27f496",
      "value": " 25.1k/? [00:00&lt;00:00, 648kB/s]"
     }
    },
    "c3fd780a91fc4afaadb6047b7d2c6bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9dcfc719ad942dcb189b667e3e795c1",
       "IPY_MODEL_006511decc0a46528da7b0ee6504f9a6",
       "IPY_MODEL_111f8108dc33411a94424555c8f61764"
      ],
      "layout": "IPY_MODEL_67738e6ae6c4491e96e6240fbde81a88"
     }
    },
    "c6b6fe27c057443aaad751c60f741a51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caa6f7cd722e4d35a552c1b038126d15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d142c4238fa948de850a0cb2edbd2505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2decb38b3054e72bc08987ce877c393": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f1cc3a8ae3c4a3fa9bc03044472681e",
      "placeholder": "​",
      "style": "IPY_MODEL_93b6776e827246a8a11afa5fb7dc022c",
      "value": " 571/571 [00:00&lt;00:00, 28.7kB/s]"
     }
    },
    "d478e7e548144f75b1f399b5719c3ffc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5ca926cf3014bb3b02213d19b5174ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5cbea18f5da44779a54e833e2c174c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da43154eeef74b12bf991f7fb0d92bdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd10fbeb89994271838ae05e88133ec6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecade8245d2d4286bec02891cf2aa663",
      "placeholder": "​",
      "style": "IPY_MODEL_5f5c2641cc2e4f769f1ed1dcf3512a76",
      "value": "Adding EOS to train dataset: 100%"
     }
    },
    "ddefb1fc45834cb5a22b9937572b96d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df0d0acfddc3464f9999162bb755135e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02c5a0ccbb554045ad4d06a8c2fe527e",
      "max": 493443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ce874e636b5431f87e3d87307c0f78a",
      "value": 493443
     }
    },
    "e0cbf4484f3643f79a5281f59e7387c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e25dcee5dc454f2686a5dda5953bca2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2b2723b0e9b402981efeeb5c03dbe71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2ca8236080e4ee9b7377f717663d598": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3192a68368043c19680533bab875978": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e3b62cec75044a3f8818088418889e1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3f5578fe80c459e8902e52046c298a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3f868262f65454c9253b2cb1d104a50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abea1734b11b48dbac39e573529a6899",
      "placeholder": "​",
      "style": "IPY_MODEL_ddefb1fc45834cb5a22b9937572b96d7",
      "value": " 47789/47789 [00:10&lt;00:00, 8325.91 examples/s]"
     }
    },
    "e5048fd751f14077bb1eabbf614f49d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e69459761c7c4d6abb0b31c53e17b25d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e84c86b72dad41358779ef8acfd76fe7",
       "IPY_MODEL_5a7e20494e6e435b886d33fd03fdbd3f",
       "IPY_MODEL_d2decb38b3054e72bc08987ce877c393"
      ],
      "layout": "IPY_MODEL_753ebf3faae646f8aaf89d17a1037c60"
     }
    },
    "e752cec41b4f4721bf7de91aead1e9c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9093f1ed697493e8a1793c379561104",
      "max": 258243053,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9706ef52c7344df0abc27510c69b8bae",
      "value": 258243053
     }
    },
    "e7e206a46c1f4ba38a84012813cd2d75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d1add9086ed469ba6050c78b2494575",
      "max": 47789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f08e4d8625b54b778519d6d44da004cc",
      "value": 47789
     }
    },
    "e84c86b72dad41358779ef8acfd76fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be8c1b2248474fb3b137bb2f3ed3f136",
      "placeholder": "​",
      "style": "IPY_MODEL_98a7565ef51b44cb838525e3b51497fb",
      "value": "config.json: 100%"
     }
    },
    "e95150bed40f410786bf37574493b6e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5f8423cf5e943f6a038834bf432e9f5",
      "placeholder": "​",
      "style": "IPY_MODEL_14da0ed71f0f472785b80fdfcd742a66",
      "value": "Truncating train dataset: 100%"
     }
    },
    "e98d34abe8a147c9a586b48ef2dd8536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c5daf8b18b64a5c927ad836159ee610",
      "placeholder": "​",
      "style": "IPY_MODEL_b4f3ac777d334459aa15db6f513ab516",
      "value": " 47789/47789 [01:57&lt;00:00, 608.09 examples/s]"
     }
    },
    "e9fcc0f4561343518f41ecfd0b35d24c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebf5ac08ec7b419ebcc607f7ce6ee267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72a8532ee2144122b5d1691868553f0a",
      "placeholder": "​",
      "style": "IPY_MODEL_23857b0b34044e94a057fd5d79a403b5",
      "value": "tokenizer.model: 100%"
     }
    },
    "ecade8245d2d4286bec02891cf2aa663": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecd267e13bc64adbab9244502a01a088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e95150bed40f410786bf37574493b6e2",
       "IPY_MODEL_e7e206a46c1f4ba38a84012813cd2d75",
       "IPY_MODEL_2b7908894f9e4011aaf12e5d59b20eeb"
      ],
      "layout": "IPY_MODEL_875de1949ab34611a345d19eb1e47d20"
     }
    },
    "ecdd75856b70440d93555b16b9f0ecde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed669c15885045969ceac20fc4d3a920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56cc182bab934d25bbf9c58fd7c48918",
       "IPY_MODEL_4878901af9034b90a4aeca3664418e7f",
       "IPY_MODEL_a476180b84834b299abc15d9d10c266a"
      ],
      "layout": "IPY_MODEL_141cf542cc8e4053b7e56a0d716edc22"
     }
    },
    "ef8907524dbe4e90af3449d32b75ae63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f08e4d8625b54b778519d6d44da004cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f25624c9a19a42eabe048d8817de859b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3528f55f4cc4423a152b68acb05bc23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2904d5798e82499ab2c78df46979aba3",
      "placeholder": "​",
      "style": "IPY_MODEL_775815fabf6f4c308ae82bcdd232e236",
      "value": "Tokenizing train dataset: 100%"
     }
    },
    "f3574491632f45b2a805c80d1168f808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4fa38cc4a964827831bc03f640d51c5",
       "IPY_MODEL_4ade69e8fccc40e39d63c2e095d0d206",
       "IPY_MODEL_56c5d2ae093c4b6890c23d9ff742c4a2"
      ],
      "layout": "IPY_MODEL_14418b67a8484f15bd7443b0ba46bf49"
     }
    },
    "f4b7a8a515174420a343fc1669f4c274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5b3ac9d591148758489b6def986ac59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f86b3883a99e498a954335e22e0bbcc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4dea8d4120cc44f887212dd985eda300",
       "IPY_MODEL_81566870baa148bbb7869d3f60be5a10",
       "IPY_MODEL_1ff1ea50838b4b169014d8358a70cff4"
      ],
      "layout": "IPY_MODEL_a4f8be4cf6ad4da89fb1259a92802cc6"
     }
    },
    "f960e5f011e0483a99394c9a6100c64f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9dcfc719ad942dcb189b667e3e795c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a6af08be437470db24d89f1bd29b7d2",
      "placeholder": "​",
      "style": "IPY_MODEL_635bebfa0b5b4f9eb2dffcc629997509",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "fab2ada1292a4452af59462d2b59f000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0cbf4484f3643f79a5281f59e7387c6",
      "max": 414,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3192a68368043c19680533bab875978",
      "value": 414
     }
    },
    "fb3b57f67fa64a7a9f8748f53abd58e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb45f6fee56b47ad92d8e0d34b20dadd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb7167302776440fa94dfe4f2466cabc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58c98d5c77124706999903e8fc7cfb76",
      "placeholder": "​",
      "style": "IPY_MODEL_04a23499a28e4563ad703d17223fd883",
      "value": "generation_config.json: 100%"
     }
    },
    "fcba1ff6aaeb465c9cda02bc7dde0692": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43a5333d499f4541908e0773a668d16e",
      "max": 47789,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3476e8392764a83a3241d553c7a49f0",
      "value": 47789
     }
    },
    "ff6deeea5a1a4117b749ee5356c1cd81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
